{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965423d1",
   "metadata": {},
   "source": [
    "# 调包与函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55489c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacleanv2 import *\n",
    "from SetRNN import *\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from collections import Counter # 用于统计计数的工具\n",
    "import time # 用于计时\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils # 用于处理变长序列，如填充和打包\n",
    "from torch.utils.data import Dataset, DataLoader # PyTorch 数据加载工具\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # 进度条库，使用 tqdm.tqdm\n",
    "import random\n",
    "import pyreadstat\n",
    "import copy # 用于复制模型参数或列表\n",
    "import matplotlib.pyplot as plt # 用于绘图\n",
    "import seaborn as sns # 用于更美观的统计图，特别是热力图\n",
    "import pickle\n",
    "plt.rcParams['font.family'] = ['SimHei'] # 使用黑体，或其他支持中文的字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像时负号'-'显示为方块的问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce99c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_with_result(result: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    将子 DataFrame 列表中的每个元素转换为一个包含时间序列结果的列表。\n",
    "\n",
    "    Args:\n",
    "        result: 包含 Pandas DataFrame 的列表。\n",
    "\n",
    "    Returns:\n",
    "        一个最终列表，其中每个元素都是一个包含时间序列 的DataFrame的列表。\n",
    "    \"\"\"\n",
    "    final_list = []\n",
    "    for df in result:\n",
    "        if not df.empty:\n",
    "            # 1. 提取时间序列数据\n",
    "            time_series_df = df[['time', 'event_value']].copy()\n",
    "            time_series_df = time_series_df.rename(columns = {\"event_value\":\"combined_setting\"})\n",
    "            final_list.append(time_series_df)\n",
    "        else:\n",
    "            final_list.append(pd.DataFrame(columns=['time','combined_setting'])) # 处理空 DataFrame\n",
    "\n",
    "    return final_list\n",
    "\n",
    "def encode_event_values(dataframes_list: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    将每个dataframe中的combined_setting列从字符串映射为0-12的数字编码\n",
    "    \n",
    "    Args:\n",
    "        dataframes_list: 包含多个dataframe的列表，每个dataframe有time和combined_setting两列\n",
    "        \n",
    "    Returns:\n",
    "        转换后的dataframe列表，combined_setting列变为数字编码\n",
    "    \"\"\"\n",
    "    # 定义映射字典\n",
    "    event_mapping = {\n",
    "        'Buy': 0,\n",
    "        'Cancel': 1,\n",
    "        'city_subway': 2,\n",
    "        'concession': 3,\n",
    "        'country_trains': 4,\n",
    "        'daily': 5,\n",
    "        'full_fare': 6,\n",
    "        'individual': 7,\n",
    "        'trip_1': 8,\n",
    "        'trip_2': 9,\n",
    "        'trip_3': 10,\n",
    "        'trip_4': 11,\n",
    "        'trip_5': 12\n",
    "    }\n",
    "\n",
    "    # 处理每个dataframe\n",
    "    encoded_dataframes = []\n",
    "    \n",
    "    for i, df in enumerate(dataframes_list):\n",
    "        # 检查dataframe结构\n",
    "        if not {'time', 'combined_setting'}.issubset(df.columns):\n",
    "            raise ValueError(f\"第{i}个dataframe缺少time或combined_setting列\")\n",
    "        # 复制dataframe以避免修改原始数据\n",
    "        df_encoded = df.copy()\n",
    "        # 映射combined_setting列\n",
    "        df_encoded['combined_setting'] = df_encoded['combined_setting'].map(event_mapping)\n",
    "        encoded_dataframes.append(df_encoded)\n",
    "    \n",
    "    return encoded_dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99c2ca",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203632be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,mata = pyreadstat.read_sav(r\"E:\\复旦大学\\研一上\\科研\\评分剪枝算法\\数据\\tickets\\CBA_cp038q01_logs12_SPSS.sav\")\n",
    "result =[item[1:-1] for item in split_strict_paired_events(df)]\n",
    "final_result_list_raw=create_time_series_with_result(result)\n",
    "transformed_list = encode_event_values(final_result_list_raw)\n",
    "filtered_dfs = [[df,''] for df in transformed_list if len(df)>=3]\n",
    "#加一个''作为response占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 0.3\n",
    "\n",
    "# 超参数和常量定义\n",
    "NUM_MAIN_MODELS = 3 # 主要的聚类模型数量\n",
    "NUM_COMBINED_SETTINGS = 13 # combined_setting 的总类别数 (1-23)\n",
    "EMBEDDING_DIM = 8 # combined_setting 的嵌入向量维度，可调整\n",
    "HIDDEN_SIZE = 64   # RNN 隐藏层大小，可调整\n",
    "NUM_RNN_LAYERS = 2 # RNN 层数\n",
    "# 注意: TIME_LOSS_SCALER 可能需要根据实际 delta_t 的规模重新调整\n",
    "TIME_LOSS_SCALER = 1 # time delta_t MSE 损失的缩放因子，需要根据实际损失值大小调整\n",
    "SETTING_LOSS_SCALER = 0 # setting 损失的缩放因子，需要根据实际损失值大小调整    \n",
    "TOTAL_EM_ITERATIONS = 10 # EM 迭代总次数 (根据要求修改为 10)\n",
    "CONVERGENCE_THRESHOLD = 0.05 # 收敛阈值，分配改变的序列比例低于此值时停止 (5%)\n",
    "\n",
    "# 干扰项处理参数\n",
    "NUM_RAND_SEQUENCES = 250 # 干扰项的已知数量\n",
    "INTERFERENCE_CLUSTER_LABEL = 3 # 将干扰项分配到的簇的索引 (0, 1, 2 是主簇，3 是干扰簇)\n",
    "INTERFERENCE_DETECTION_START_ITER = 2 # 从第 5 轮迭代 (索引 4) 的 E 步开始检测干扰项\n",
    "# 检测干扰项的高损失阈值：需要根据训练中观察到的损失值范围来调整\n",
    "# 如果一个序列在所有模型上的平均损失超过这个阈值，则可能被认为是干扰项。\n",
    "# ！！！重要参数，需要根据实际运行观察的损失值调整！！！\n",
    "# 在模拟数据上运行一次，观察损失值的分布，尤其是 rand_label 序列的损失。\n",
    "HIGH_AVG_LOSS_THRESHOLD = 0.5 ## <--- !!! 初始值，请务必根据实际情况调整 !!!\n",
    "\n",
    "# M 步训练参数 (每个 EM 迭代中的训练 epochs)\n",
    "# epochs 计划表：根据迭代次数使用不同数量的 epochs\n",
    "EPOCH_SCHEDULE = [1] * 5 + [2]* 5 # 示例：前 3 轮迭代训练 2 epoch，接下来 7 轮训练 5 epoch (适应总迭代 10)\n",
    "BATCH_SIZE = 32 # M 步训练时的批次大小\n",
    "# 在早期迭代中是否只使用部分批次来加速训练\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 1 # 在启用部分批次训练时使用的批次比例 (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fdb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数声明\n",
    "\n",
    "class SettingPredictorRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, num_rnn_layers, num_categories):\n",
    "        super(SettingPredictorRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "        # 输入是 当前时间差 delta_t (1维) 和 combined_setting 的嵌入向量 (embedding_dim 维)\n",
    "        # 模型会根据当前时间差、设置和历史预测下一个时间步的时间差和设置\n",
    "        self.setting_embedding = nn.Embedding(num_categories, embedding_dim)\n",
    "        input_size = 1 + embedding_dim\n",
    "\n",
    "        # 使用 GRU 作为 RNN 层\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_rnn_layers, batch_first=True)\n",
    "\n",
    "        # 输出层\n",
    "        # 预测下一个时间步的时间差 delta_t (回归问题，输出 1维)\n",
    "        self.time_delta_output = nn.Linear(hidden_size, 1)\n",
    "        # 预测下一个 combined_setting (分类问题，输出 num_categories 维的 logits)\n",
    "        self.setting_output = nn.Linear(hidden_size, num_categories)\n",
    "\n",
    "    # 前向传播，处理填充后的批次序列\n",
    "    def forward(self, time_delta_seq, setting_seq, lengths, hidden_state=None):\n",
    "        # time_delta_seq 形状: (batch_size, seq_len) - 填充后的 当前时间差 序列\n",
    "        # setting_seq 形状: (batch_size, seq_len) - 填充后的 当前 setting 整数索引序列 (long tensor)\n",
    "        # lengths: 原始输入序列长度的列表或 tensor (对应 time_delta_seq 和 setting_seq 的长度)\n",
    "\n",
    "        # 将 setting 整数索引转换为嵌入向量\n",
    "        setting_embedded = self.setting_embedding(setting_seq) # 形状: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # 组合当前时间差输入和嵌入后的 setting\n",
    "        input_seq = torch.cat((time_delta_seq.unsqueeze(-1), setting_embedded), dim=-1) # 形状: (batch_size, seq_len, 1 + embedding_dim)\n",
    "\n",
    "        # 打包填充后的序列\n",
    "        # lengths 必须在 CPU 上\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # 通过 RNN 层\n",
    "        packed_output, hidden_state = self.rnn(packed_input, hidden_state)\n",
    "\n",
    "        # 将打包的序列重新填充回原始形状\n",
    "        output_seq, _ = rnn_utils.pad_packed_sequence(packed_output, batch_first=True, total_length=input_seq.size(1)) # 形状: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # 通过输出层进行预测\n",
    "        # 预测的是下一个时间步的 delta_t (即输入序列中当前步对应的下一个 delta_t)\n",
    "        predicted_next_delta_t = self.time_delta_output(output_seq) # 形状: (batch_size, seq_len, 1)\n",
    "        # 预测的是下一个 setting 的 logits (即输入序列中当前步对应的下一个 setting)\n",
    "        predicted_next_setting_logits = self.setting_output(output_seq) # 形状: (batch_size, seq_len, num_categories)\n",
    "\n",
    "        # 压缩 predicted_next_delta_t 的最后一维\n",
    "        predicted_next_delta_t = predicted_next_delta_t.squeeze(-1) # 形状: (batch_size, seq_len)\n",
    "\n",
    "        return predicted_next_delta_t, predicted_next_setting_logits, hidden_state\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. 准备数据加载器 SequenceDataset 和 Collate Function (在 collate_fn 中计算 delta_t 输入和目标)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        自定义数据集类。\n",
    "        Args:\n",
    "            data_list: DataFrame 列表，每个 DataFrame 代表一个序列。\n",
    "                       DataFrame 应包含 'time' (float) 和\n",
    "                       'combined_setting' (类别类型，类别为 0-124 的整数) 列。\n",
    "                       注意：time 到 delta_t 的转换在 collate_fn 中完成。\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = self.data_list[idx]\n",
    "        # 将整个 'time' 和 'combined_setting' 序列返回\n",
    "        time_seq = torch.FloatTensor(df['time'].values)\n",
    "        setting_seq = torch.LongTensor(df['combined_setting'].astype(int).values) # 确保是 LongTensor 用于 embedding\n",
    "\n",
    "        # 返回完整序列数据和原始长度\n",
    "        return time_seq, setting_seq, len(df)\n",
    "\n",
    "# 批处理数据的 Collate Function\n",
    "def collate_fn(batch):\n",
    "    # batch 是一个元组列表：[(time_seq_1, setting_seq_1, len_1), ...]\n",
    "\n",
    "    # 根据原始序列长度降序排序批次\n",
    "    batch.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # 解压批次数据\n",
    "    time_seqs_list, setting_seqs_list, original_lengths = zip(*batch)\n",
    "\n",
    "    # 过滤掉原始长度小于 3 的序列，这些序列无法构建有效的输入和目标序列 (长度 original_length - 2)\n",
    "    valid_indices = [i for i, length in enumerate(original_lengths) if length >= 3]\n",
    "\n",
    "    if not valid_indices:\n",
    "        # 如果批次中没有长度 >= 3 的序列，返回 None 表示空批次\n",
    "        return None\n",
    "\n",
    "    # 提取有效的序列和长度\n",
    "    time_seqs_list = [time_seqs_list[i] for i in valid_indices]\n",
    "    setting_seqs_list = [setting_seqs_list[i] for i in valid_indices]\n",
    "    valid_original_lengths = [original_lengths[i] for i in valid_indices]\n",
    "\n",
    "\n",
    "    # --- 计算输入序列 (当前 delta_t 和 setting) 和目标序列 (下一个 delta_t 和 setting) ---\n",
    "    # 它们都对应原始序列长度 - 2 的部分\n",
    "\n",
    "    # delta_t 输入: time[i+1] - time[i] for i from 0 to original_length - 3\n",
    "    delta_t_inputs_list = [(seq[1:-1] - seq[:-2]) for seq in time_seqs_list]\n",
    "    # setting 输入: setting[i] for i from 0 to original_length - 3\n",
    "    setting_inputs_list = [seq[:-2] for seq in setting_seqs_list]\n",
    "\n",
    "    # delta_t 目标: time[i+2] - time[i+1] for i from 0 to original_length - 3\n",
    "    delta_t_targets_list = [(seq[2:] - seq[1:-1]) for seq in time_seqs_list]\n",
    "    # setting 目标: setting[i+1] for i from 0 to original_length - 3\n",
    "    setting_targets_list = [seq[1:-1] for seq in setting_seqs_list]\n",
    "\n",
    "\n",
    "    # 输入/目标序列的长度都等于 original_length - 2\n",
    "    input_lengths = [length - 2 for length in valid_original_lengths]\n",
    "\n",
    "\n",
    "    # 填充输入序列\n",
    "    delta_t_inputs_padded = rnn_utils.pad_sequence(delta_t_inputs_list, batch_first=True, padding_value=0.0)\n",
    "    setting_inputs_padded = rnn_utils.pad_sequence(setting_inputs_list, batch_first=True, padding_value=0)\n",
    "\n",
    "    # 填充目标序列\n",
    "    delta_t_targets_padded = rnn_utils.pad_sequence(delta_t_targets_list, batch_first=True, padding_value=0.0)\n",
    "    setting_targets_padded = rnn_utils.pad_sequence(setting_targets_list, batch_first=True, padding_value=0)\n",
    "\n",
    "\n",
    "    # 输入序列的有效长度\n",
    "    input_lengths_tensor = torch.LongTensor(input_lengths)\n",
    "\n",
    "    # 根据输入序列的有效长度重新排序批次\n",
    "    sorted_lengths, sorted_indices = torch.sort(input_lengths_tensor, descending=True)\n",
    "\n",
    "    # 按照 sorted_indices 对所有张量进行排序\n",
    "    delta_t_inputs_padded = delta_t_inputs_padded[sorted_indices]\n",
    "    setting_inputs_padded = setting_inputs_padded[sorted_indices]\n",
    "    delta_t_targets_padded = delta_t_targets_padded[sorted_indices]\n",
    "    setting_targets_padded = setting_targets_padded[sorted_indices]\n",
    "\n",
    "    # 将张量移动到设备\n",
    "    delta_t_inputs_padded = delta_t_inputs_padded.to(device)\n",
    "    setting_inputs_padded = setting_inputs_padded.to(device)\n",
    "    delta_t_targets_padded = delta_t_targets_padded.to(device)\n",
    "    setting_targets_padded = setting_targets_padded.to(device)\n",
    "    # sorted_lengths 保持在 CPU\n",
    "\n",
    "    # 返回 delta_t 输入, setting 输入, delta_t 目标, setting 目标, 输入长度\n",
    "    return delta_t_inputs_padded, setting_inputs_padded, delta_t_targets_padded, setting_targets_padded, sorted_lengths\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. 实现训练函数 train_model (使用 delta_t 目标计算时间预测损失)\n",
    "#    接收模型索引作为参数进行打印。\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def train_model(model, model_idx, dataloader, optimizer, time_criterion, setting_criterion, epochs, time_scaler,setting_scaler, iteration_num):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    total_batches = len(dataloader)\n",
    "    # 根据迭代次数决定使用的批次数量\n",
    "    if iteration_num < EARLY_ITER_BATCH_THRESHOLD:\n",
    "        batches_to_use = max(1, int(total_batches * EARLY_ITER_BATCH_PERCENT))\n",
    "    else:\n",
    "        batches_to_use = total_batches\n",
    "\n",
    "    # 使用 tqdm 显示 epoch 进度，使用传入的 model_idx\n",
    "    epoch_tqdm = tqdm(range(epochs), desc=f\"迭代 {iteration_num} (模型 {model_idx}) 训练\", leave=False)\n",
    "    for epoch in epoch_tqdm:\n",
    "        batch_count = 0\n",
    "        # 使用 tqdm 显示批次进度\n",
    "        batch_tqdm = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_data in batch_tqdm:\n",
    "            if batch_data is None: continue # 跳过空批次\n",
    "\n",
    "            # 从 collate_fn 获取批次数据\n",
    "            # 获取的是 delta_t 输入\n",
    "            delta_t_inputs, setting_inputs, delta_t_targets, setting_targets, lengths = batch_data\n",
    "\n",
    "            optimizer.zero_grad() # 清零梯度\n",
    "\n",
    "            # 前向传播\n",
    "            # 模型现在输出的是 predicted_next_delta_t 和 predicted_next_setting_logits\n",
    "            predicted_next_delta_t, predicted_next_setting_logits, _ = model(delta_t_inputs, setting_inputs, lengths)\n",
    "\n",
    "            # 计算损失\n",
    "            # predicted_next_delta_t 形状: (batch_size, seq_len)\n",
    "            # delta_t_targets 形状: (batch_size, seq_len)\n",
    "            time_loss = time_criterion(predicted_next_delta_t, delta_t_targets)\n",
    "\n",
    "            # predicted_next_setting_logits 形状: (batch_size, seq_len, num_categories)\n",
    "            # setting_targets 形状: (batch_size, seq_len)\n",
    "            # 需要调整 logits 的维度到 (batch_size, num_categories, seq_len)\n",
    "            setting_loss = setting_criterion(predicted_next_setting_logits.permute(0, 2, 1), setting_targets)\n",
    "\n",
    "            # 计算总损失，并应用时间损失缩放因子\n",
    "            loss = time_loss * time_scaler + setting_loss*setting_scaler\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            # 可选：梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_count += 1\n",
    "            # 在早期迭代中，只训练部分批次\n",
    "            if batch_count >= batches_to_use:\n",
    "                 break\n",
    "\n",
    "            # 更新批次进度条的后缀信息（可选）\n",
    "            batch_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 更新 epoch 进度条的后缀信息（可选）\n",
    "        # 注意：这里显示的是最后一个批次的损失，不是平均损失\n",
    "        epoch_tqdm.set_postfix(last_batch_loss=loss.item())\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. 实现评估函数 evaluate_sequence_loss (计算单个序列 **平均** 损失)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_sequence_loss(model, time_seq_full, setting_seq_full, time_criterion, setting_criterion, time_scaler,setting_scaler):\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "\n",
    "        seq_len = time_seq_full.size(0)\n",
    "        # 序列长度小于 3 无法构建输入和目标序列 (长度 original_length - 2)\n",
    "        if seq_len < 3:\n",
    "            # 返回无穷大，表示无法计算有效损失，在比较时会被排除\n",
    "            return float('inf')\n",
    "\n",
    "        # --- 构建输入序列 (当前 delta_t 和 setting) 和目标序列 (下一个 delta_t 和 setting) ---\n",
    "        # 它们都对应原始序列长度 - 2 的部分\n",
    "\n",
    "        # delta_t 输入: time[i+1] - time[i] for i from 0 to seq_len - 3\n",
    "        delta_t_inputs_sliced = (time_seq_full[1:-1] - time_seq_full[:-2]).unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "        # setting 输入: setting[i] for i from 0 to seq_len - 3\n",
    "        setting_inputs_sliced = setting_seq_full[:-2].unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "\n",
    "        # delta_t 目标: time[i+2] - time[i+1] for i from 0 to seq_len - 3\n",
    "        delta_t_targets_sliced = (time_seq_full[2:] - time_seq_full[1:-1]).unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "        # setting 目标: setting[i+1] for i from 0 to seq_len - 3\n",
    "        setting_targets_sliced = setting_seq_full[1:-1].unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "\n",
    "        # 输入序列的实际长度\n",
    "        eval_input_len = seq_len - 2 # 有效的预测步数\n",
    "        lengths = torch.tensor([eval_input_len]) # 保持在 CPU\n",
    "\n",
    "        # 前向传播，计算整个序列的预测结果 (长度为 eval_input_len)\n",
    "        predicted_next_delta_t, predicted_next_setting_logits, _ = model(delta_t_inputs_sliced, setting_inputs_sliced, lengths)\n",
    "\n",
    "        # 计算整个序列的损失 (注意：损失函数如 MSELoss 和 CrossEntropyLoss 默认计算的是批次和序列长度上的平均)\n",
    "        # 但在这里我们处理的是单个序列 (batch_size = 1)，并且使用了 pack_padded_sequence，\n",
    "        # PyTorch 会确保损失计算只在有效长度上进行。\n",
    "        # 所以 time_criterion(predicted_next_delta_t, delta_t_targets_sliced) 计算的是 batch 和 有效长度上的平均损失。\n",
    "        # setting_criterion(...) 也类似。\n",
    "\n",
    "        time_loss = time_criterion(predicted_next_delta_t, delta_t_targets_sliced)\n",
    "        setting_loss = setting_criterion(predicted_next_setting_logits.permute(0, 2, 1), setting_targets_sliced)\n",
    "\n",
    "        # 计算总损失 (按步加权平均)\n",
    "        total_loss_per_step = time_loss * time_scaler + setting_loss\n",
    "\n",
    "        # total_loss_per_step 现在已经是每个预测步的平均损失了 (因为 MSELoss/CrossEntropyLoss 默认对 batch 和序列长度取平均)\n",
    "        # 但是 pack_padded_sequence 的行为可能会影响这个平均，为了安全和明确，我们还是按总损失再除以步数\n",
    "        # 更稳妥的方法是使用 reduction='sum' 然后手动除以有效步数\n",
    "        time_criterion_sum = nn.MSELoss(reduction='sum')\n",
    "        setting_criterion_sum = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        time_loss_sum = time_criterion_sum(predicted_next_delta_t, delta_t_targets_sliced)\n",
    "        setting_loss_sum = setting_criterion_sum(predicted_next_setting_logits.permute(0, 2, 1), setting_targets_sliced)\n",
    "\n",
    "        total_sum_loss = time_loss_sum * time_scaler + setting_loss_sum * setting_scaler\n",
    "    \n",
    "        # 计算 **平均** 损失：总和损失除以有效预测步数\n",
    "        average_loss_per_step = total_sum_loss / eval_input_len\n",
    "        average_set_loss_per_step = setting_loss_sum / eval_input_len\n",
    "\n",
    "\n",
    "        # 返回标量平均损失值\n",
    "        return average_loss_per_step.item(),average_set_loss_per_step.item()\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5. 实现 EM-like 聚类算法 run_rnn_clustering (加入干扰项处理)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def run_rnn_clustering(transformed_list, num_main_models, embedding_dim, hidden_size, num_rnn_layers,\n",
    "                       num_categories, time_scaler,setting_scaler, total_iterations, convergence_threshold,\n",
    "                       epoch_schedule, batch_size, early_iter_batch_threshold, early_iter_batch_percent,\n",
    "                       interference_cluster_label, interference_detection_start_iter, high_avg_loss_threshold, num_rand_sequences):\n",
    "\n",
    "    total_sequences = len(transformed_list)\n",
    "    print(f\"开始基于 RNN 的聚类，共有 {total_sequences} 条序列，聚成 {num_main_models} 类 + 1 干扰类 ({interference_cluster_label})。\")\n",
    "\n",
    "    # 1. 初始化\n",
    "    # 创建 NUM_MAIN_MODELS 个结构相同的 RNN 模型\n",
    "    models = [SettingPredictorRNN(embedding_dim, hidden_size, num_rnn_layers, num_categories).to(device) for _ in range(num_main_models)]\n",
    "\n",
    "    # current_assignments: 存储当前迭代中用于 M 步训练和 E 步重新分配的簇分配 (0, 1, 2, 或 interference_cluster_label)。\n",
    "    # 初始化时，所有序列随机分配到主簇。长度不足 3 的序列暂时分配到 -1。\n",
    "    current_assignments = np.full(total_sequences, -1, dtype=int) # 初始化为 -1\n",
    "    # 先将长度 >= 3 的序列随机分配到主簇\n",
    "    long_enough_indices = np.where(np.array([len(item[0]) for item in transformed_list]) >= 3)[0]\n",
    "    current_assignments[long_enough_indices] = np.random.randint(0, num_main_models, len(long_enough_indices))\n",
    "\n",
    "\n",
    "    print(f\"初始随机分配到主簇 (长度>=3 的序列): {np.bincount(current_assignments[current_assignments != -1], minlength=num_main_models)}\")\n",
    "    print(f\"初始未分配序列 (长度<3): {np.sum(current_assignments == -1)}\")\n",
    "\n",
    "\n",
    "    # 定义损失函数 (用于 E 步计算单序列损失，使用 reduction='sum')\n",
    "    time_criterion_sum = nn.MSELoss(reduction='sum')\n",
    "    setting_criterion_sum = nn.CrossEntropyLoss(reduction='sum')\n",
    "    # 定义损失函数 (用于 M 步训练批次，使用默认 reduction='mean')\n",
    "    time_criterion_mean = nn.MSELoss()\n",
    "    setting_criterion_mean = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # 记录被标记为干扰项的序列的原始索引 (仅用于跟踪和最终返回)\n",
    "    removed_interference_indices_tracker = []\n",
    "\n",
    "    # 2. EM-like 迭代循环\n",
    "    main_tqdm = tqdm(range(total_iterations), desc=\"EM 迭代总进度\")\n",
    "    for iter_num in main_tqdm:\n",
    "        main_tqdm.set_description(f\"EM 迭代 {iter_num + 1}/{total_iterations}\")\n",
    "\n",
    "        # prev_assignments: 记录本轮迭代 E 步开始前 current_assignments 的状态，用于收敛检查 (仅检查主簇变化)\n",
    "        prev_assignments = current_assignments.copy()\n",
    "\n",
    "        # active_indices: 获取当前仍在参与聚类的主簇序列的原始索引 (即 current_assignments != interference_cluster_label 的序列)\n",
    "        active_indices_mask = (current_assignments != interference_cluster_label) & (current_assignments != -1) # 排除已标记为干扰项和尚未初始分配的 (-1)\n",
    "        active_indices = np.where(active_indices_mask)[0]\n",
    "        current_total_active_sequences = len(active_indices)\n",
    "\n",
    "\n",
    "        # 只有当还有活跃序列时才进行 M 步训练\n",
    "        if current_total_active_sequences > 0:\n",
    "             print(f\"\\n--- 迭代 {iter_num + 1}: M 步 (训练模型)，当前活跃序列数: {current_total_active_sequences} ---\")\n",
    "             # 获取本轮迭代应训练的 epochs 数量\n",
    "             current_epochs = epoch_schedule[min(iter_num, len(epoch_schedule) - 1)]\n",
    "\n",
    "             # M 步: 根据 current_assignments 训练每个模型 (仅使用活跃序列)\n",
    "             for model_idx in range(num_main_models):\n",
    "                 # 找到当前分配给该模型的所有 *活跃* 序列的原始索引\n",
    "                 assigned_indices_in_active = active_indices[current_assignments[active_indices] == model_idx]\n",
    "\n",
    "                 if len(assigned_indices_in_active) == 0:\n",
    "                     print(f\"  模型 {model_idx} 没有活跃序列分配到，跳过训练。\")\n",
    "                     continue\n",
    "\n",
    "                 # 获取这些索引对应的原始数据框\n",
    "                 # Dataset 会只加载这些索引对应的 df\n",
    "                 assigned_dataset = SequenceDataset([transformed_list[i][0] for i in assigned_indices_in_active])\n",
    "                 # collate_fn 将过滤掉长度不足 3 的序列，DataLoader 会处理批次和填充\n",
    "                 assigned_dataloader = DataLoader(assigned_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "                 # 只有当 DataLoader 不为空时才训练 (即存在长度 >= 3 的序列)\n",
    "                 if len(assigned_dataloader) > 0:\n",
    "                    # 为当前模型创建一个优化器\n",
    "                    optimizer = optim.Adam(models[model_idx].parameters())\n",
    "\n",
    "                    # 调用训练函数训练当前模型，传入模型索引，使用 mean reduction 的损失函数\n",
    "                    train_model(models[model_idx], model_idx, assigned_dataloader, optimizer,\n",
    "                                time_criterion_mean, setting_criterion_mean, current_epochs,\n",
    "                                time_scaler, setting_scaler,iter_num)\n",
    "                 else:\n",
    "                     print(f\"  模型 {model_idx} 分配到的活跃序列中没有长度 >= 3 的，跳过训练。\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n--- 迭代 {iter_num + 1}: M 步 (训练模型)，当前没有活跃序列，跳过训练。---\")\n",
    "            # 如果没有活跃序列，且不是第一轮，可能已经收敛或所有都被标记为干扰项\n",
    "            if iter_num > 0:\n",
    "                 print(\"\\n没有活跃序列，且不是第一轮迭代，可能已收敛。\")\n",
    "                 break # 跳出循环\n",
    "\n",
    "\n",
    "        print(f\"\\n--- 迭代 {iter_num + 1}: E 步 (重分配序列及干扰项检测) ---\")\n",
    "\n",
    "        # 在 E 步开始时，找出所有未被最终标记为干扰项的序列 (可能包含长度不足 3 的)\n",
    "        # 这些是 candidates for re-assignment or interference detection\n",
    "        candidate_indices_mask = (current_assignments != interference_cluster_label) # 只要不是干扰项，都是候选\n",
    "        candidate_indices = np.where(candidate_indices_mask)[0]\n",
    "        current_total_candidates = len(candidate_indices)\n",
    "\n",
    "        if current_total_candidates == 0:\n",
    "             print(\"  当前没有候选序列需要评估 (所有序列都已标记为干扰项)。\")\n",
    "             break # 跳出循环\n",
    "\n",
    "        # 计算所有 *候选* 序列在所有主模型上的损失 (使用 sum reduction 的损失函数)\n",
    "        # losses_for_candidates 形状: (当前候选序列总数, 主模型总数)\n",
    "        losses_for_candidates = np.full((current_total_candidates, num_main_models), float('inf')) # 初始化为无穷大\n",
    "        set_losses_for_candidates = np.full((current_total_candidates, num_main_models), float('inf'))\n",
    "        print(f\"  计算 {current_total_candidates} 条候选序列在每个模型上的平均损失...\")\n",
    "        eval_tqdm = tqdm(range(current_total_candidates), desc=\"计算损失\", leave=False)\n",
    "        for j in eval_tqdm:\n",
    "             original_idx = candidate_indices[j] # 获取对应的原始索引\n",
    "             df = transformed_list[original_idx][0] # 获取数据框\n",
    "\n",
    "             time_seq_full = torch.FloatTensor(df['time'].values)\n",
    "             setting_seq_full = torch.LongTensor(df['combined_setting'].astype(int).values)\n",
    "\n",
    "             # evaluate_sequence_loss 内部会检查长度是否 >= 3，并返回 inf 或平均损失\n",
    "             for model_idx in range(num_main_models):\n",
    "                 # evaluate_sequence_loss 现在返回的是平均损失\n",
    "                 avg_loss,set_loss = evaluate_sequence_loss(models[model_idx], time_seq_full, setting_seq_full,\n",
    "                                                   time_criterion_sum, setting_criterion_sum, time_scaler,setting_scaler)\n",
    "                 losses_for_candidates[j, model_idx],set_losses_for_candidates[j, model_idx] = avg_loss,set_loss # 记录平均损失\n",
    "\n",
    "        # --- 干扰项检测和移除 ---\n",
    "        # 在指定迭代轮次之后进行干扰项检测\n",
    "        if iter_num >= interference_detection_start_iter -1 :\n",
    "            print(\"  进行干扰项检测...\")\n",
    "            # 只考虑那些所有模型损失都不是无穷大的候选序列 (即长度 >= 3 的序列)\n",
    "            valid_loss_candidate_indices_relative = np.where(np.isfinite(losses_for_candidates).all(axis=1))[0]\n",
    "            # 对应的原始索引\n",
    "            valid_loss_candidates_original_indices = candidate_indices[valid_loss_candidate_indices_relative]\n",
    "            # 对应的平均损失矩阵 (只包含长度 >= 3 的序列)\n",
    "            valid_avg_losses = losses_for_candidates[valid_loss_candidate_indices_relative]\n",
    "            set_avg_losses = set_losses_for_candidates[valid_loss_candidate_indices_relative]\n",
    "\n",
    "            if len(valid_loss_candidate_indices_relative) > 0:\n",
    "                 # 计算这些序列在所有主模型上的 平均平均损失 (只是为了排序，不是必须的)\n",
    "                 min_of_avg_losses_valid_candidates = valid_avg_losses.var(axis=1)#改：应该计算所有主模型中的最低损失而非平均损失\n",
    "\n",
    "                 # 识别 平均损失 的 平均值 高于阈值的有效损失候选序列的索引 (在 valid_loss_candidate_indices_relative 中的相对索引)\n",
    "                 high_avg_loss_valid_candidate_indices_relative_to_valid = np.where(min_of_avg_losses_valid_candidates > high_avg_loss_threshold)[0]\n",
    "\n",
    "                 # 将这些高平均损失有效候选序列的相对索引映射回原始索引\n",
    "                 high_avg_loss_candidates_original_indices = valid_loss_candidates_original_indices[high_avg_loss_valid_candidate_indices_relative_to_valid]\n",
    "\n",
    "\n",
    "                 # 从高平均损失候选者中，选取平均损失最高的序列作为干扰项\n",
    "                 # 确保不超过已知干扰项总数 (num_rand_sequences)，并且不重复移除\n",
    "                 # 找到尚未被标记为干扰项的高平均损失候选者\n",
    "                 currently_not_removed_high_avg_loss_mask = np.isin(high_avg_loss_candidates_original_indices, removed_interference_indices_tracker, invert=True)\n",
    "                 currently_not_removed_high_avg_loss_original_indices = high_avg_loss_candidates_original_indices[currently_not_removed_high_avg_loss_mask]\n",
    "\n",
    "                 # 对这些尚未被移除的高平均损失序列，按平均损失的平均值降序排序\n",
    "                 # 需要获取这些序列在 min_of_avg_losses_valid_candidates 中的对应值\n",
    "                 # 找到 currently_not_removed_high_avg_loss_original_indices 在 valid_loss_candidates_original_indices 中的相对索引\n",
    "                 relative_indices_in_valid_for_candidates_to_sort = np.where(np.isin(valid_loss_candidates_original_indices, currently_not_removed_high_avg_loss_original_indices))[0]\n",
    "                 min_of_avg_losses_for_sorting = min_of_avg_losses_valid_candidates[relative_indices_in_valid_for_candidates_to_sort]\n",
    "                 # 对原始索引进行排序，基于其对应的平均损失的平均值\n",
    "                 #sorted_candidates_original_indices = currently_not_removed_high_avg_loss_original_indices[np.argsort(min_of_avg_losses_for_sorting)[::-1]]\n",
    "                 sorted_candidates_original_indices = currently_not_removed_high_avg_loss_original_indices[np.argsort(min_of_avg_losses_for_sorting) ]\n",
    "\n",
    "             \n",
    "                 # 选取前 N 个作为本轮被标记为干扰项的序列\n",
    "                 num_to_select_this_iter = min(len(sorted_candidates_original_indices), num_rand_sequences - len(removed_interference_indices_tracker),20)\n",
    "                 indices_to_remove_this_iter_original = sorted_candidates_original_indices[:num_to_select_this_iter]#每轮最多标记20个\n",
    "\n",
    "                 # 将这些序列标记为干扰项 (在 current_assignments 中设置为干扰簇标签)\n",
    "                 current_assignments[indices_to_remove_this_iter_original] = interference_cluster_label\n",
    "                 # 添加到已移除列表中 (跟踪用)\n",
    "                 removed_interference_indices_tracker.extend(indices_to_remove_this_iter_original)\n",
    "                 removed_count_this_iter = len(indices_to_remove_this_iter_original)\n",
    "                 print(f\"  本轮标记 {removed_count_this_iter} 条序列为干扰项。总计已标记 {len(removed_interference_indices_tracker)} 条。\")\n",
    "            else:\n",
    "                 print(\"  没有符合高平均损失阈值的候选序列 (长度 >= 3)，本轮未标记新的干扰项。\")\n",
    "        else:\n",
    "            print(\"  干扰项检测尚未开始。\")\n",
    "\n",
    "\n",
    "        # --- 主簇重新分配 ---\n",
    "        # 找到当前仍未被标记为干扰项的序列 (这些是需要重新分配到主簇或保持主簇分配的序列)\n",
    "        remaining_main_cluster_candidate_indices_mask = (current_assignments != interference_cluster_label) # 修复：只要不是干扰项，都是候选\n",
    "        remaining_main_cluster_candidate_indices = np.where(remaining_main_cluster_candidate_indices_mask)[0]\n",
    "\n",
    "\n",
    "        # 从 losses_for_candidates 中，提取出这些剩余主簇候选序列的损失\n",
    "        # losses_for_candidates 的行是按照 E 步开始时的 candidate_indices 的顺序排列的\n",
    "        # 找到 remaining_main_cluster_candidate_indices 在 E 步开始时的 candidate_indices 中的位置 (相对索引)\n",
    "        relative_indices_in_candidates_for_remaining = np.where(np.isin(candidate_indices, remaining_main_cluster_candidate_indices))[0]\n",
    "        losses_for_remaining_main_candidates = losses_for_candidates[relative_indices_in_candidates_for_remaining]\n",
    "\n",
    "        # 只对那些有有效平均损失的序列 (长度 >= 3) 进行重新分配 (排除 inf)\n",
    "        valid_loss_remaining_mask = np.isfinite(losses_for_remaining_main_candidates).all(axis=1)\n",
    "        valid_loss_remaining_relative_indices_in_candidates = relative_indices_in_candidates_for_remaining[valid_loss_remaining_mask]\n",
    "        valid_loss_remaining_original_indices = candidate_indices[valid_loss_remaining_relative_indices_in_candidates] # 这些是需要重新分配的序列的原始索引\n",
    "\n",
    "\n",
    "        if len(valid_loss_remaining_original_indices) > 0:\n",
    "             # 找到这些序列在三个主模型上的 **平均损失** 最小的模型索引 (0, 1, 或 2)\n",
    "             losses_for_valid_remaining = losses_for_candidates[valid_loss_remaining_relative_indices_in_candidates]\n",
    "             new_main_assignments_for_valid_remaining = losses_for_valid_remaining.argmin(axis=1)\n",
    "\n",
    "             # 更新这些序列在 current_assignments 中的分组 (设置为 0, 1, 或 2)\n",
    "             current_assignments[valid_loss_remaining_original_indices] = new_main_assignments_for_valid_remaining\n",
    "\n",
    "             print(f\"  {len(valid_loss_remaining_original_indices)} 条长度 >= 3 的序列被重新分配到主簇。\")\n",
    "\n",
    "        else:\n",
    "             print(\"  没有长度 >= 3 的序列需要重新分配到主簇。\")\n",
    "\n",
    "\n",
    "        # 检查收敛性：比较本轮迭代 E 步开始前和结束后的 current_assignments (仅考虑主簇)\n",
    "        # 找到在两轮迭代中都未被标记为干扰项的序列的原始索引\n",
    "        stable_indices_mask = (prev_assignments != interference_cluster_label) & (current_assignments != interference_cluster_label) & (prev_assignments != -1) & (current_assignments != -1) # 修复：排除-1的序列\n",
    "        stable_indices = np.where(stable_indices_mask)[0]\n",
    "\n",
    "        if len(stable_indices) > 0:\n",
    "            # 比较这些稳定序列在两轮迭代中的主簇分配\n",
    "            prev_main_assignments_stable = prev_assignments[stable_indices]\n",
    "            current_main_assignments_stable = current_assignments[stable_indices]\n",
    "\n",
    "            # 计算改变主簇分配的序列数量 (仅在稳定序列中)\n",
    "            num_changes = np.sum(prev_main_assignments_stable != current_main_assignments_stable)\n",
    "            # 计算改变分组的序列比例 (基于总序列数)\n",
    "            change_percent = num_changes / total_sequences\n",
    "\n",
    "            print(f\"  未被标记干扰项且已分配到主簇的序列中，有 {num_changes} 条改变了主簇 ({change_percent:.2%})。\")\n",
    "\n",
    "            # 判断是否收敛：如果改变比例低于阈值，且不是第一轮迭代 (iter_num > 0)\n",
    "            if change_percent < convergence_threshold and iter_num > 0:\n",
    "                print(f\"收敛达成。总分组改变比例 ({change_percent:.2%}) 低于阈值 ({convergence_threshold:.2%})。\")\n",
    "                break\n",
    "        elif iter_num > 0: # 如果没有稳定序列，且不是第一轮\n",
    "             print(\"  没有稳定序列 (未被标记干扰项且已分配到主簇)，无法计算收敛率。\")\n",
    "             pass # 继续迭代或添加其他条件\n",
    "\n",
    "        else: # 第一轮迭代结束，没有上一轮状态进行比较\n",
    "             print(\"  第一轮迭代结束，无法计算收敛率。\")\n",
    "\n",
    "\n",
    "        # 打印当前的分组统计 (包含干扰项和未分配的 -1)\n",
    "        print(f\"  当前分组统计: {np.bincount(current_assignments + 1, minlength=num_main_models + 2)}\") # +1 让 -1 变为 0，0 变为 1 等，minlength 确保包含所有可能的类别\n",
    "        print(f\"    (-1: {np.sum(current_assignments == -1)}, 0-{num_main_models-1}: {np.bincount(current_assignments[current_assignments >= 0], minlength=num_main_models)[:num_main_models]}, {interference_cluster_label}: {np.sum(current_assignments == interference_cluster_label)})\")\n",
    "\n",
    "\n",
    "        # 如果达到最大迭代次数\n",
    "        if iter_num == total_iterations - 1:\n",
    "             print(\"达到最大迭代次数。\")\n",
    "\n",
    "        main_tqdm.update(0) # 更新主进度条显示的信息 (主要是当前迭代数)\n",
    "\n",
    "    # 迭代结束\n",
    "    # 将最终的 current_assignments 赋值给 final_assignments\n",
    "    final_assignments = current_assignments.copy()\n",
    "\n",
    "    # 将剩余未分配的序列 (-1) 也标记为干扰项\n",
    "    remaining_unassigned_indices = np.where(final_assignments == -1)[0]\n",
    "    if len(remaining_unassigned_indices) > 0:\n",
    "        print(f\"迭代结束，将剩余 {len(remaining_unassigned_indices)} 条未分配序列标记为干扰项。\")\n",
    "        final_assignments[remaining_unassigned_indices] = interference_cluster_label\n",
    "        # 添加到最终跟踪列表中\n",
    "        # 修复：只添加尚未被标记为干扰项的未分配序列\n",
    "        already_removed_mask = np.isin(remaining_unassigned_indices, removed_interference_indices_tracker)\n",
    "        newly_removed_indices = remaining_unassigned_indices[~already_removed_mask]\n",
    "        removed_interference_indices_tracker.extend(newly_removed_indices)\n",
    "\n",
    "\n",
    "    print(\"\\n--- 聚类完成 ---\")\n",
    "    # 最终分组统计 (包含干扰项)\n",
    "    assigned_indices_mask = final_assignments != -1\n",
    "    if assigned_indices_mask.sum() > 0:\n",
    "        final_clusters_counts = np.bincount(final_assignments[assigned_indices_mask], minlength=num_main_models + 1)\n",
    "        print(f\"最终各簇包含的序列数量 (0-{num_main_models-1} 是主簇, {interference_cluster_label} 是干扰簇):\")\n",
    "        print(f\"簇 0-{num_main_models-1}: {final_clusters_counts[:num_main_models]}, 干扰项 ({interference_cluster_label}): {final_clusters_counts[interference_cluster_label] if interference_cluster_label < len(final_clusters_counts) else 0}\")\n",
    "    else:\n",
    "        print(\"最终所有序列都未被分配到任何簇。\")\n",
    "\n",
    "\n",
    "    return models, final_assignments, removed_interference_indices_tracker # 返回 models\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6. 聚类结果可视化函数 (包含干扰项类别)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def visualize_clustering_results(transformed_list, final_assignments, num_main_models, interference_cluster_label):\n",
    "    \"\"\"\n",
    "    可视化聚类结果，显示原始标签与分配到的簇之间的交叉关系 (包含干扰项类别)。\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 聚类结果可视化 ---\")\n",
    "\n",
    "    original_labels = [item[1] for item in transformed_list] # 提取所有原始标签\n",
    "    # 根据最终分组创建分组标签 (0, 1, 2 对应主簇，干扰簇使用单独标签)\n",
    "    assignment_labels = [f\"簇_{a}\" if a != interference_cluster_label else \"干扰项\" for a in final_assignments]\n",
    "\n",
    "    # 创建原始标签和分配簇的 DataFrame\n",
    "    results_df = pd.DataFrame({'原始标签': original_labels, '分配到的簇': assignment_labels})\n",
    "\n",
    "    # 确保交叉表中包含所有可能的原始标签和所有可能的分配簇标签\n",
    "    all_original_labels = sorted(list(set(original_labels))) # 包含 onestep, repeat, reset, rand\n",
    "    all_assignment_labels = [f\"簇_{i}\" for i in range(num_main_models)] + [\"干扰项\"]\n",
    "    # 确保 '干扰项' 标签在分配簇中存在，即使没有序列被分到，以便reindex不出错\n",
    "    if \"干扰项\" not in all_assignment_labels:\n",
    "         all_assignment_labels.append(\"干扰项\")\n",
    "    # 按照簇号排序主簇标签，干扰项放最后\n",
    "    all_assignment_labels = sorted(all_assignment_labels, key=lambda x: int(x.split('_')[1]) if x.startswith('簇_') else 999)\n",
    "\n",
    "\n",
    "    # 计算交叉表\n",
    "    # .reindex 确保行和列按照指定的顺序和名称显示，没有的填 0\n",
    "    crosstab_df = pd.crosstab(results_df['原始标签'], results_df['分配到的簇']).reindex(index=all_original_labels, columns=all_assignment_labels, fill_value=0)\n",
    "\n",
    "    print(\"\\n原始标签与分配到的簇的交叉表:\")\n",
    "    print(crosstab_df)\n",
    "\n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(10, 7)) # 调整图大小以容纳更多标签\n",
    "    sns.heatmap(crosstab_df, annot=True, fmt='d', cmap='Blues', linewidths=.5)\n",
    "    plt.title('原始标签与分配到的簇的交叉表', fontsize=14)\n",
    "    plt.xlabel('分配到的簇', fontsize=12)\n",
    "    plt.ylabel('原始标签', fontsize=12)\n",
    "    plt.tight_layout() # 自动调整布局，防止标签重叠\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7. 单样本步进式预测函数及可视化 (仅针对非干扰项)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def predict_sequence_step_by_step(model, dataframe, num_categories):\n",
    "    \"\"\"\n",
    "    使用模型对单个序列进行步进式预测，并返回实际值和预测值。\n",
    "    预测的输入是当前 delta_t 和 setting，预测下一个 delta_t 和 setting。\n",
    "    实际预测时间需要根据实际时间进行累加。\n",
    "\n",
    "    Args:\n",
    "        model: 训练好的 RNN 模型。\n",
    "        dataframe: 单个序列的 DataFrame，包含 'time' (绝对时间) 和 'combined_setting' 列。\n",
    "        num_categories: setting 的总类别数 (125)。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (actual_time_sliced, predicted_time_abs, actual_setting_sliced, predicted_setting)\n",
    "               actual_time_sliced: 实际的时间序列 (从原始序列索引 1 开始) (numpy array)\n",
    "               predicted_time_abs: 预测的绝对时间序列 (从原始序列索引 1 开始) (numpy array)\n",
    "               actual_setting_sliced: 实际的设置序列 (从原始序列索引 1 开始) (numpy array, 整数 0-124)\n",
    "               predicted_setting: 预测的设置序列 (从原始序列索引 1 开始) (numpy array, 整数 0-124)\n",
    "               注意：预测序列和切片的实际序列长度是 seq_len - 1。\n",
    "               如果无法预测 (序列太短)，返回 None, None, None, None。\n",
    "    \"\"\"\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "\n",
    "        # 确保 dataframe 长度足够进行预测 (至少需要 2 步才能计算第一个 delta_t 并预测下一步)\n",
    "        seq_len = len(dataframe)\n",
    "        if seq_len < 2: # 修复：预测一步需要至少 2个点\n",
    "            return None, None, None, None\n",
    "\n",
    "        # 提取实际序列值\n",
    "        actual_time = dataframe['time'].values.astype(np.float32)\n",
    "        actual_setting = dataframe['combined_setting'].astype(int).values.astype(np.int64) # 确保是整数类型\n",
    "\n",
    "        # 初始化存储预测结果的列表\n",
    "        predicted_delta_t_list = []\n",
    "        predicted_setting_list = []\n",
    "\n",
    "        # 初始化 RNN 的隐藏状态\n",
    "        hidden_state = None # GRU 的隐藏状态可以是 None\n",
    "\n",
    "        # 步进式预测循环：\n",
    "        # 循环遍历实际序列，从第一个时间步 (索引 i=0) 作为模型的输入起点\n",
    "        # 输入到模型的是 actual_time[i+1]-actual_time[i] (delta_t 输入) 和 actual_setting[i] (setting 输入)\n",
    "        # 预测的是 actual_time[i+2]-actual_time[i+1] (预测 delta_t) 和 actual_setting[i+1] (预测 setting)\n",
    "        # 循环范围是 i 从 0 到 seq_len - 2 (共 seq_len - 1 步预测)\n",
    "        # 第 i 步的输入：actual_time[i+1]-actual_time[i] 和 actual_setting[i]\n",
    "        # 预测输出对应实际序列的索引 i+1 的时间差和设置\n",
    "\n",
    "        # 需要实际序列的前 seq_len - 1 个 delta_t 作为模型的输入序列\n",
    "        actual_delta_t_inputs_for_rnn = actual_time[1:] - actual_time[:-1] # 形状: (seq_len - 1)\n",
    "        # 需要实际序列的前 seq_len - 1 个 setting 作为模型的输入序列\n",
    "        actual_setting_inputs_for_rnn = actual_setting[:-1] # 形状: (seq_len - 1)\n",
    "\n",
    "        # 模型输入序列长度\n",
    "        rnn_input_len = seq_len - 1\n",
    "\n",
    "        # 将整个输入序列一次性输入到模型中，获取所有预测结果\n",
    "        # 这是模拟 RNN 的序列处理，而不是真正的单步循环预测\n",
    "        # 如果想做真正的单步预测，需要循环并手动管理 hidden_state\n",
    "        # 为了可视化对比所有步的预测，一次性输入更方便\n",
    "\n",
    "        # 准备输入张量 (增加批次维)\n",
    "        delta_t_inputs_tensor = torch.tensor(actual_delta_t_inputs_for_rnn, dtype=torch.float32).unsqueeze(0).to(device) # Shape: (1, seq_len - 1)\n",
    "        setting_inputs_tensor = torch.tensor(actual_setting_inputs_for_rnn, dtype=torch.long).unsqueeze(0).to(device) # Shape: (1, seq_len - 1)\n",
    "\n",
    "        # 准备 lengths tensor\n",
    "        lengths_tensor = torch.tensor([rnn_input_len]) # 保持在 CPU\n",
    "\n",
    "        # 将隐藏状态移动到设备\n",
    "        hidden_state = hidden_state.to(device) if hidden_state is not None else None\n",
    "\n",
    "        # 通过 RNN 进行前向传播\n",
    "        # 模型输出的是 predicted_next_delta_t 和 predicted_next_setting_logits\n",
    "        # predicted_next_delta_t 形状: (1, rnn_input_len)\n",
    "        # predicted_next_setting_logits 形状: (1, rnn_input_len, num_categories)\n",
    "        predicted_next_delta_t_seq, predicted_next_setting_logits_seq, _ = model(delta_t_inputs_tensor, setting_inputs_tensor, lengths_tensor, hidden_state)\n",
    "\n",
    "        # 转换为 numpy 数组\n",
    "        predicted_delta_t = predicted_next_delta_t_seq.squeeze(0).cpu().numpy() # Shape: (rnn_input_len,) = (seq_len - 1,)\n",
    "        predicted_setting = torch.argmax(predicted_next_setting_logits_seq.squeeze(0), dim=-1).cpu().numpy() # Shape: (rnn_input_len,) = (seq_len - 1,)\n",
    "\n",
    "        # 计算预测的绝对时间序列 (从 actual_time[1] 开始)\n",
    "        # predicted_time_abs[i] = actual_time[i] + predicted_delta_t[i] (i from 0 to seq_len-2)\n",
    "        predicted_time_abs = actual_time[:-1] + predicted_delta_t # Shape: (seq_len - 1)\n",
    "\n",
    "\n",
    "        # 实际的时间和设置序列需要截取到预测结果的长度一致 (从第二个元素开始)\n",
    "        # 预测序列长度是 seq_len - 1\n",
    "        # 它们预测的是 actual_time[1:] 的绝对时间和 actual_setting[1:] 的设置\n",
    "        actual_time_sliced = actual_time[1:] # 形状: (seq_len - 1)\n",
    "        actual_setting_sliced = actual_setting[1:] # 形状: (seq_len - 1)\n",
    "\n",
    "\n",
    "        return actual_time_sliced, predicted_time_abs, actual_setting_sliced, predicted_setting\n",
    "\n",
    "\n",
    "def visualize_prediction(actual_time, predicted_time, actual_setting, predicted_setting, sample_index, original_label, assigned_cluster_label):\n",
    "    \"\"\"\n",
    "    可视化单个序列的实际值与模型预测值的对比。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 序列 {sample_index} (原始标签: {original_label}, 分配到: {assigned_cluster_label}) 的步进式预测可视化 ---\")\n",
    "\n",
    "    # 获取预测序列的步数\n",
    "    num_steps_predicted = len(predicted_time)\n",
    "    if num_steps_predicted == 0:\n",
    "        print(\"没有可预测的步数来可视化。\")\n",
    "        return\n",
    "    # 创建 x 轴的步数索引 (从 1 开始，对应原始序列的索引 1 到 seq_len - 1)\n",
    "    step_indices = np.arange(1, num_steps_predicted + 1)\n",
    "\n",
    "    # 绘制时间预测对比图\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(step_indices, actual_time, label='实际时间', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(step_indices, predicted_time, label='预测时间', marker='x', linestyle='--', color='red')\n",
    "    plt.title(f'序列 {sample_index} 时间预测对比 (实际 vs 预测)')\n",
    "    plt.xlabel('预测步数 (对应原始序列索引 1 至末尾)')\n",
    "    plt.ylabel('时间')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制设置预测对比图\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # combined_setting 的值域是 0-124，直接作为 y 轴值\n",
    "    plt.plot(step_indices, actual_setting, label='实际设置', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(step_indices, predicted_setting, label='预测设置', marker='x', linestyle='--', color='red')\n",
    "    plt.title(f'序列 {sample_index} 设置预测对比 (实际 vs 预测)')\n",
    "    plt.xlabel('预测步数 (对应原始序列索引 1 至末尾)')\n",
    "    plt.ylabel('Combined Setting (0-124)')\n",
    "    # 可以设置 y 轴刻度，如果需要更精细的展示\n",
    "    # plt.yticks(np.arange(0, 125, 10)) # 示例：每隔 10 个类别显示一个刻度\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "setting_categories = [-2, -1, 0, 1, 2] # 假设这是您的原始 setting categories\n",
    "# 创建一个有序的 CategoricalDtype\n",
    "setting_dtype = pd.CategoricalDtype(categories=setting_categories, ordered=True)\n",
    "\n",
    "def restore_from_transformed_element(transformed_element):\n",
    "    \"\"\"\n",
    "    将一个转换后的数据元素 (来自 transformed_list) 还原为原始格式。\n",
    "\n",
    "    Args:\n",
    "        transformed_element: 列表，一个元素来自 transformed_list，格式为\n",
    "                             [transformed_dataframe, label]。\n",
    "                             transformed_dataframe 包含 'time', 'combined_setting' 列。\n",
    "                             'combined_setting' 列是 dtype='category'，其类别是 0-124 的整数。\n",
    "\n",
    "    Returns:\n",
    "        list: 还原后的元素，格式为 [restored_dataframe, label]。\n",
    "              restored_dataframe 包含 'time', 'top_setting', 'central_setting',\n",
    "              'bottom_setting' 列。这三列是 dtype='category'，其类别是 -2到2。\n",
    "    Raises:\n",
    "        ValueError: 如果输入格式不正确。\n",
    "    \"\"\"\n",
    "    if not isinstance(transformed_element, list) or len(transformed_element) != 2:\n",
    "        raise ValueError(\"Input must be a list of two elements: [dataframe, label]\")\n",
    "\n",
    "    transformed_df, label = transformed_element\n",
    "\n",
    "    if not isinstance(transformed_df, pd.DataFrame):\n",
    "         raise ValueError(\"First element of the input list must be a pandas DataFrame\")\n",
    "\n",
    "    if not all(col in transformed_df.columns for col in ['time', 'combined_setting']):\n",
    "         raise ValueError(\"Input DataFrame must contain 'time' and 'combined_setting' columns\")\n",
    "\n",
    "    # 确保 'combined_setting' 是 category 类型，并且其类别是整数 (0-124)\n",
    "    # 使用 .astype(int) 来获取其内部整数表示\n",
    "    try:\n",
    "        combined_values = transformed_df['combined_setting'].astype(int)\n",
    "    except ValueError as e:\n",
    "         raise ValueError(f\"Could not convert 'combined_setting' to int, check category values: {e}\")\n",
    "\n",
    "\n",
    "    # 逆转五进制编码 (分解)\n",
    "    # combined_setting_id = mapped_top * 25 + mapped_central * 5 + mapped_bottom * 1\n",
    "    # mapped values are 0-4, corresponding to -2 to 2\n",
    "\n",
    "    mapped_top = combined_values // 25         # 整数除法\n",
    "    remainder = combined_values % 25           # 取余数\n",
    "    mapped_central = remainder // 5\n",
    "    mapped_bottom = remainder % 5              # 或者 remainder // 1, 但 % 5 更清晰表示末位\n",
    "\n",
    "    # 逆转映射 (将 0-4 还原到 -2-2)\n",
    "    top_setting_numeric = mapped_top - 2\n",
    "    central_setting_numeric = mapped_central - 2\n",
    "    bottom_setting_numeric = mapped_bottom - 2\n",
    "\n",
    "    # 创建新的 DataFrame，包含原始 time 和还原后的三列设置\n",
    "    restored_df = pd.DataFrame({\n",
    "        'time': transformed_df['time'],\n",
    "        'top_setting': top_setting_numeric,\n",
    "        'central_setting': central_setting_numeric,\n",
    "        'bottom_setting': bottom_setting_numeric\n",
    "    })\n",
    "\n",
    "    # 将还原后的设置列转换为 category 类型，使用之前定义的有序类别和 dtype\n",
    "    for col in ['top_setting', 'central_setting', 'bottom_setting']:\n",
    "        # 确保转换后的数值在 [-2, 2] 范围内，否则 astype(setting_dtype) 可能产生 NaN\n",
    "        # 如果编码正确，这应该是保证的\n",
    "        try:\n",
    "            restored_df[col] = restored_df[col].astype(setting_dtype)\n",
    "        except ValueError as e:\n",
    "             print(f\"警告: 还原列 '{col}' 包含超出类别范围的值，转换为 category 时可能出现 NaN: {e}\")\n",
    "             restored_df[col] = pd.Categorical(restored_df[col], categories=setting_categories, ordered=True) # 即使有超出范围的也尝试转换\n",
    "\n",
    "    # 返回还原后的 [dataframe, label] 元素\n",
    "    return [restored_df, label]\n",
    "\n",
    "def calculate_row_condition_proportion(data_list, condition_func):\n",
    "    \"\"\"\n",
    "    计算一个列表中的所有 DataFrame 合并后，满足特定行条件的比例。\n",
    "\n",
    "    Args:\n",
    "        data_list: 列表，每个元素是 [dataframe, label]。\n",
    "        condition_func: 一个函数，接收一个 DataFrame 的行 (Pandas Series)，返回 True 或 False。\n",
    "\n",
    "    Returns:\n",
    "        float: 满足条件的行数 / 总行数。如果总行数为 0，返回 0.0。\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for df, _ in data_list:\n",
    "        if df is not None and not df.empty:\n",
    "             # 确保只选择 setting 列\n",
    "             all_rows.append(df[['top_setting', 'central_setting', 'bottom_setting']].astype(int)) # 将 category 转为 int 进行计算\n",
    "\n",
    "    if not all_rows:\n",
    "        return 0.0 # 没有数据框或数据框为空\n",
    "\n",
    "    combined_df = pd.concat(all_rows, ignore_index=True)\n",
    "    total_rows = len(combined_df)\n",
    "\n",
    "    if total_rows == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # 使用 apply along axis 1 to check condition for each row\n",
    "    # condition_func will receive a Series representing a row of setting columns\n",
    "    # pandas apply can be slow, but for clarity let's use it first.\n",
    "    # A vectorized approach is better if possible.\n",
    "\n",
    "    # Vectorized approach for the specific conditions required:\n",
    "\n",
    "    # Condition: exactly one setting is non-zero\n",
    "    if condition_func.__name__ == 'is_one_setting_nonzero':\n",
    "         # Count non-zero settings in each row (0 for non-zero, 1 for zero)\n",
    "         # Summing booleans treats True as 1, False as 0\n",
    "         num_nonzero = (combined_df != 0).sum(axis=1) # axis=1 sums across columns for each row\n",
    "         satisfied_rows = (num_nonzero == 1).sum() # Count rows where num_nonzero is exactly 1\n",
    "\n",
    "    # Condition: any setting is 1 or -1\n",
    "    elif condition_func.__name__ == 'is_any_setting_1_or_neg1':\n",
    "         # Check if any setting in the row is 1 or -1\n",
    "         is_1_or_neg1 = combined_df.isin([1, -1]) # Boolean DataFrame of same shape\n",
    "         satisfied_rows = is_1_or_neg1.any(axis=1).sum() # Check if 'any' is True in each row, then sum\n",
    "\n",
    "    else:\n",
    "         # Fallback to apply for general condition functions (less efficient)\n",
    "         print(f\"警告: 使用通用的 apply 方法计算条件 '{condition_func.__name__}' 的比例，效率较低。\")\n",
    "         satisfied_rows = combined_df.apply(condition_func, axis=1).sum()\n",
    "\n",
    "\n",
    "    return satisfied_rows / total_rows\n",
    "\n",
    "\n",
    "# Helper condition functions for clarity\n",
    "def is_one_setting_nonzero(row):\n",
    "     # row is a Pandas Series of shape (3,) representing ['top', 'central', 'bottom'] settings\n",
    "     # Convert to numpy array for boolean calculation\n",
    "     settings = row.values\n",
    "     # Count how many settings are not equal to 0\n",
    "     num_nonzero = np.sum(settings != 0)\n",
    "     return num_nonzero == 1\n",
    "\n",
    "def is_any_setting_1_or_neg1(row):\n",
    "    # row is a Pandas Series of shape (3,)\n",
    "    settings = row.values\n",
    "    # Check if any setting is equal to 1 or -1\n",
    "    return np.any((settings == 1) | (settings == -1))\n",
    "\n",
    "\n",
    "def calculate_label_proportion(data_list, target_label):\n",
    "    \"\"\"\n",
    "    计算一个列表中元素标签为特定字符串的比例。\n",
    "\n",
    "    Args:\n",
    "        data_list: 列表，每个元素是 [dataframe, label]。\n",
    "        target_label: 目标标签字符串。\n",
    "\n",
    "    Returns:\n",
    "        float: 标签为 target_label 的元素数量 / 列表总元素数量。如果列表为空，返回 0.0。\n",
    "    \"\"\"\n",
    "    total_elements = len(data_list)\n",
    "    if total_elements == 0:\n",
    "        return 0.0\n",
    "\n",
    "    target_label_count = sum(1 for df, label in data_list if label == target_label)\n",
    "\n",
    "    return target_label_count / total_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7482fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_list = filtered_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb806f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:总共生成 31322 条模拟序列 (0 条干扰项)。\n",
      "\n",
      "--- 运行基于 RNN (预测 delta_t) 的聚类算法 (带干扰项处理) ---\n",
      "开始基于 RNN 的聚类，共有 31322 条序列，聚成 3 类 + 1 干扰类 (3)。\n",
      "初始随机分配到主簇 (长度>=3 的序列): [10638 10274 10410]\n",
      "初始未分配序列 (长度<3): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fc9e4070b54378871917ca6900ecd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EM 迭代总进度:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 1: M 步 (训练模型)，当前活跃序列数: 31322 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3894573786014a01bb598f407819b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cc426158974e258bbf2550d8dc0f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b41c14c17124863a7db0367a6b0de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04160275abd84915a874ad3e4c535cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa6934c7e5f45d9abb2c86617570886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf27fe98e8e451b880fbcf0979acc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 1: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31322 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f5b2b3524f48db83839166130749d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  干扰项检测尚未开始。\n",
      "  31322 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 20498 条改变了主簇 (65.44%)。\n",
      "  当前分组统计: [    0 13523  8209  9590     0]\n",
      "    (-1: 0, 0-2: [13523  8209  9590], 3: 0)\n",
      "\n",
      "--- 迭代 2: M 步 (训练模型)，当前活跃序列数: 31322 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690ba4c469d745289a7e014bd0e832d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c3247bf0154a7382e5652754de9d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e907abb5b14843a419def5b99aa7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ea484f83424cc4b1a0f15c763e5ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc070790d14766aa648017ab44a530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdcf796419d46779e0995f09d299c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 2: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31322 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5005f75579455a8a26424ad2006654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 20 条。\n",
      "  31302 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 7464 条改变了主簇 (23.83%)。\n",
      "  当前分组统计: [    0 10727  9606 10969    20]\n",
      "    (-1: 0, 0-2: [10727  9606 10969], 3: 20)\n",
      "\n",
      "--- 迭代 3: M 步 (训练模型)，当前活跃序列数: 31302 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a54c360fe4452593d50713a721cb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91494b1b2cb46fd804a7107e71c4071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a0ed267052490f9c1c2fe08a337887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f9149d1ec64bad8a1c37ece4c280b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a73d21b8a97408d902cda52191a3840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b341100b6e0343dd81a8cd4d847adff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 3: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31302 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde9fb9ac1e8455cbf2854d3b1d79017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 40 条。\n",
      "  31282 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 4415 条改变了主簇 (14.10%)。\n",
      "  当前分组统计: [    0  8831 10527 11924    40]\n",
      "    (-1: 0, 0-2: [ 8831 10527 11924], 3: 40)\n",
      "\n",
      "--- 迭代 4: M 步 (训练模型)，当前活跃序列数: 31282 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf6b45eaf3a46b5ac18c7d091860538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7639c80485445794be2b8ef9f7d47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81338343ad3461a943e36b1189b8d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa2305e868445a8a2c4d822ff45f912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aafb633bb124a49b061d0b7080be27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df17a73d1b2c4509ab3335ee446df103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 4: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31282 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aebc2b19817451bb6a69816ac8cd1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 60 条。\n",
      "  31262 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 2494 条改变了主簇 (7.96%)。\n",
      "  当前分组统计: [    0  8649 10523 12090    60]\n",
      "    (-1: 0, 0-2: [ 8649 10523 12090], 3: 60)\n",
      "\n",
      "--- 迭代 5: M 步 (训练模型)，当前活跃序列数: 31262 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb47922c56354f4299eb0d2e6ea1eac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 4 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7752856ad79249de9051b56598fafe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/271 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a52bc5cb494ca1babbf1b392bf5547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 4 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d13eabffc64d50a20f8051ff4ec2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461df440d442478c89d810dc65bdf58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 4 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b380d675de84a6eb4565507744cdc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 5: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31262 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849d550442c34c51a777b2374ae63256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 80 条。\n",
      "  31242 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 2258 条改变了主簇 (7.21%)。\n",
      "  当前分组统计: [    0  8208 10290 12744    80]\n",
      "    (-1: 0, 0-2: [ 8208 10290 12744], 3: 80)\n",
      "\n",
      "--- 迭代 6: M 步 (训练模型)，当前活跃序列数: 31242 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5444d6c123314e34a05d3f2ae1f9dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 5 (模型 0) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca84ddffe3643c0a764a5bb34ecbfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209ec18698eb4c74808a02be9c7da08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e9fb71dc5f40a38399ed95d94222b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 5 (模型 1) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0789c2d1ea5414d8f0f5ac9eb190f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034c9f526bc944338b495bf99d01450a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac278128a544b8cb7a9089af5131058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 5 (模型 2) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da38088529f44865aea723eb0de1a18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dacc68c14c4b56b3804887d9250123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 6: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31242 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b940b760c6a34f13b6f554b24c0a0f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 100 条。\n",
      "  31222 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 1748 条改变了主簇 (5.58%)。\n",
      "  当前分组统计: [    0  8083 10245 12894   100]\n",
      "    (-1: 0, 0-2: [ 8083 10245 12894], 3: 100)\n",
      "\n",
      "--- 迭代 7: M 步 (训练模型)，当前活跃序列数: 31222 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1a50aa004a48fd86c81b36d55e9bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 6 (模型 0) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c63849d5b54b7fbe4f801a8b55f46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a287a7d6cd64ae6bbd1bef5c59ae421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77894623abc349688440cf9902d7b30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 6 (模型 1) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ef6bd282c843a9afbb94b4e28065ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/321 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e308c3f7d24cddb00e839d57e87e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/321 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7190c03a8bc486aa995a433a4f91a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 6 (模型 2) 训练:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dcac06ee8544f983373c27dfbfc57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9863a6d053f74b248ca9ffb35b7bb51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 7: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31222 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577533df640a4fc089ccacef785c2d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 120 条。\n",
      "  31202 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 978 条改变了主簇 (3.12%)。\n",
      "收敛达成。总分组改变比例 (3.12%) 低于阈值 (5.00%)。\n",
      "\n",
      "--- 聚类完成 ---\n",
      "最终各簇包含的序列数量 (0-2 是主簇, 3 是干扰簇):\n",
      "簇 0-2: [ 8077 10351 12774], 干扰项 (3): 120\n",
      "\n",
      "--- 聚类结果可视化 ---\n",
      "\n",
      "原始标签与分配到的簇的交叉表:\n",
      "分配到的簇   簇_0    簇_1    簇_2  干扰项\n",
      "原始标签                          \n",
      "       8077  10351  12774  120\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seeds=0\n",
    "while(1):\n",
    "    seeds +=1000\n",
    "    random.seed(seeds)\n",
    "    np.random.seed(seeds)\n",
    "    torch.manual_seed(seeds)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seeds)\n",
    "        torch.backends.cudnn.deterministic = True # 确保 CUDA 确定性算法\n",
    "    \n",
    "    TOTAL_SEQUENCES = len(transformed_list) # 更新总序列数常量\n",
    "\n",
    "    print(f\"{seeds}:总共生成 {TOTAL_SEQUENCES} 条模拟序列 ({len([item for item in transformed_list if item[1] == \"rand_label\"])} 条干扰项)。\")\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 运行聚类算法\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    print(f\"\\n--- 运行基于 RNN (预测 delta_t) 的聚类算法 (带干扰项处理) ---\")\n",
    "    # 修复：将 high_loss_threshold 参数名改为 high_avg_loss_threshold\n",
    "    final_models, final_assignments, removed_interference_indices_final = run_rnn_clustering(\n",
    "        transformed_list=transformed_list,\n",
    "        num_main_models=NUM_MAIN_MODELS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_rnn_layers=NUM_RNN_LAYERS,\n",
    "        num_categories=NUM_COMBINED_SETTINGS,\n",
    "        time_scaler=TIME_LOSS_SCALER, # 注意：这里可能需要根据实际 delta_t 值的范围调整 scaler\n",
    "        setting_scaler=SETTING_LOSS_SCALER,\n",
    "        total_iterations=TOTAL_EM_ITERATIONS, # 使用更新后的迭代次数\n",
    "        convergence_threshold=CONVERGENCE_THRESHOLD,\n",
    "        epoch_schedule=EPOCH_SCHEDULE, # 使用更新后的 epoch 计划表\n",
    "        batch_size=BATCH_SIZE,\n",
    "        early_iter_batch_threshold=EARLY_ITER_BATCH_THRESHOLD, # 使用更新后的阈值\n",
    "        early_iter_batch_percent=EARLY_ITER_BATCH_PERCENT,\n",
    "        interference_cluster_label=INTERFERENCE_CLUSTER_LABEL, # 干扰项簇标签\n",
    "        interference_detection_start_iter=INTERFERENCE_DETECTION_START_ITER, # 干扰项检测起始迭代\n",
    "        high_avg_loss_threshold=HIGH_AVG_LOSS_THRESHOLD, # 高平均损失阈值\n",
    "        num_rand_sequences=NUM_RAND_SEQUENCES # 已知的干扰项数量 (用于选出最高损失的 N 个)\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 聚类结果可视化 (包含干扰项类别)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    visualize_clustering_results(transformed_list, final_assignments, NUM_MAIN_MODELS, INTERFERENCE_CLUSTER_LABEL)\n",
    "    # 初始化四个空列表，对应簇 0, 1, 2 和 3 (干扰项)\n",
    "    # 这些列表将存储还原后的 [dataframe, label] 元素\n",
    "    cluster_1 = [] # 对应簇 0\n",
    "    cluster_2 = [] # 对应簇 1\n",
    "    cluster_3 = [] # 对应簇 2\n",
    "    trival_cluster = [] # 对应簇 3 (干扰项)\n",
    "\n",
    "    # 创建一个字典，将簇索引映射到对应的列表\n",
    "    cluster_map = {\n",
    "        0: cluster_1,\n",
    "        1: cluster_2,\n",
    "        2: cluster_3,\n",
    "        INTERFERENCE_CLUSTER_LABEL: trival_cluster # 使用常量\n",
    "    }\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b209bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=final_models[0]\n",
    "model2=final_models[1]\n",
    "model3=final_models[2]\n",
    "\n",
    "torch.save(model1,\"model1_tickets.pth\")\n",
    "torch.save(model2,\"model2_tickets.pth\")\n",
    "torch.save(model3,\"model3_tickets.pth\")\n",
    "np.save(\"Final_assignments_tickets.npy\", final_assignments)\n",
    "with open('LoadedList_Climate.pkl', 'wb') as file:\n",
    "    pickle.dump(transformed_list, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
