{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965423d1",
   "metadata": {},
   "source": [
    "# 调包与函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55489c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacleanv2 import *\n",
    "from SetRNN import *\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from collections import Counter # 用于统计计数的工具\n",
    "import time # 用于计时\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils # 用于处理变长序列，如填充和打包\n",
    "from torch.utils.data import Dataset, DataLoader # PyTorch 数据加载工具\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # 进度条库，使用 tqdm.tqdm\n",
    "import random\n",
    "import pyreadstat\n",
    "import copy # 用于复制模型参数或列表\n",
    "import matplotlib.pyplot as plt # 用于绘图\n",
    "import seaborn as sns # 用于更美观的统计图，特别是热力图\n",
    "import pickle\n",
    "plt.rcParams['font.family'] = ['SimHei'] # 使用黑体，或其他支持中文的字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像时负号'-'显示为方块的问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bce99c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_with_result(result: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    将子 DataFrame 列表中的每个元素转换为一个包含时间序列结果的列表。\n",
    "\n",
    "    Args:\n",
    "        result: 包含 Pandas DataFrame 的列表。\n",
    "\n",
    "    Returns:\n",
    "        一个最终列表，其中每个元素都是一个包含时间序列 的DataFrame的列表。\n",
    "    \"\"\"\n",
    "    final_list = []\n",
    "    for df in result:\n",
    "        if not df.empty:\n",
    "            # 1. 提取时间序列数据\n",
    "            time_series_df = df[['time', 'event_value']].copy()\n",
    "            time_series_df = time_series_df.rename(columns = {\"event_value\":\"combined_setting\"})\n",
    "            final_list.append(time_series_df)\n",
    "        else:\n",
    "            final_list.append(pd.DataFrame(columns=['time','combined_setting'])) # 处理空 DataFrame\n",
    "\n",
    "    return final_list\n",
    "\n",
    "def encode_event_values(dataframes_list: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    将每个dataframe中的combined_setting列从字符串映射为0-12的数字编码\n",
    "    \n",
    "    Args:\n",
    "        dataframes_list: 包含多个dataframe的列表，每个dataframe有time和combined_setting两列\n",
    "        \n",
    "    Returns:\n",
    "        转换后的dataframe列表，combined_setting列变为数字编码\n",
    "    \"\"\"\n",
    "    # 定义映射字典\n",
    "    event_mapping = {\n",
    "        'Buy': 0,\n",
    "        'Cancel': 1,\n",
    "        'city_subway': 2,\n",
    "        'concession': 3,\n",
    "        'country_trains': 4,\n",
    "        'daily': 5,\n",
    "        'full_fare': 6,\n",
    "        'individual': 7,\n",
    "        'trip_1': 8,\n",
    "        'trip_2': 9,\n",
    "        'trip_3': 10,\n",
    "        'trip_4': 11,\n",
    "        'trip_5': 12\n",
    "    }\n",
    "\n",
    "    # 处理每个dataframe\n",
    "    encoded_dataframes = []\n",
    "    \n",
    "    for i, df in enumerate(dataframes_list):\n",
    "        # 检查dataframe结构\n",
    "        if not {'time', 'combined_setting'}.issubset(df.columns):\n",
    "            raise ValueError(f\"第{i}个dataframe缺少time或combined_setting列\")\n",
    "        # 复制dataframe以避免修改原始数据\n",
    "        df_encoded = df.copy()\n",
    "        # 映射combined_setting列\n",
    "        df_encoded['combined_setting'] = df_encoded['combined_setting'].map(event_mapping)\n",
    "        encoded_dataframes.append(df_encoded)\n",
    "    \n",
    "    return encoded_dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99c2ca",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "203632be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,mata = pyreadstat.read_sav(r\"E:\\复旦大学\\研一上\\科研\\评分剪枝算法\\数据\\tickets\\CBA_cp038q01_logs12_SPSS.sav\")\n",
    "result =[item[1:-1] for item in split_strict_paired_events(df)]\n",
    "final_result_list_raw=create_time_series_with_result(result)\n",
    "transformed_list = encode_event_values(final_result_list_raw)\n",
    "filtered_dfs = [[df,''] for df in transformed_list if len(df)>=3]\n",
    "#加一个''作为response占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 0.3\n",
    "\n",
    "# 超参数和常量定义\n",
    "NUM_MAIN_MODELS = 3 # 主要的聚类模型数量\n",
    "NUM_COMBINED_SETTINGS = 13 # combined_setting 的总类别数 (1-23)\n",
    "EMBEDDING_DIM = 8 # combined_setting 的嵌入向量维度，可调整\n",
    "HIDDEN_SIZE = 64   # RNN 隐藏层大小，可调整\n",
    "NUM_RNN_LAYERS = 2 # RNN 层数\n",
    "# 注意: TIME_LOSS_SCALER 可能需要根据实际 delta_t 的规模重新调整\n",
    "TIME_LOSS_SCALER = 0 # time delta_t MSE 损失的缩放因子，需要根据实际损失值大小调整\n",
    "SETTING_LOSS_SCALER = 1 # setting 损失的缩放因子，需要根据实际损失值大小调整    \n",
    "TOTAL_EM_ITERATIONS = 10 # EM 迭代总次数 (根据要求修改为 10)\n",
    "CONVERGENCE_THRESHOLD = 0.05 # 收敛阈值，分配改变的序列比例低于此值时停止 (5%)\n",
    "\n",
    "# 干扰项处理参数\n",
    "NUM_RAND_SEQUENCES = 250 # 干扰项的已知数量\n",
    "INTERFERENCE_CLUSTER_LABEL = 3 # 将干扰项分配到的簇的索引 (0, 1, 2 是主簇，3 是干扰簇)\n",
    "INTERFERENCE_DETECTION_START_ITER = 2 # 从第 5 轮迭代 (索引 4) 的 E 步开始检测干扰项\n",
    "# 检测干扰项的高损失阈值：需要根据训练中观察到的损失值范围来调整\n",
    "# 如果一个序列在所有模型上的平均损失超过这个阈值，则可能被认为是干扰项。\n",
    "# ！！！重要参数，需要根据实际运行观察的损失值调整！！！\n",
    "# 在模拟数据上运行一次，观察损失值的分布，尤其是 rand_label 序列的损失。\n",
    "HIGH_AVG_LOSS_THRESHOLD = 0.5 ## <--- !!! 初始值，请务必根据实际情况调整 !!!\n",
    "\n",
    "# M 步训练参数 (每个 EM 迭代中的训练 epochs)\n",
    "# epochs 计划表：根据迭代次数使用不同数量的 epochs\n",
    "EPOCH_SCHEDULE = [1] * 5 + [2]* 5 # 示例：前 3 轮迭代训练 2 epoch，接下来 7 轮训练 5 epoch (适应总迭代 10)\n",
    "BATCH_SIZE = 32 # M 步训练时的批次大小\n",
    "# 在早期迭代中是否只使用部分批次来加速训练\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 1 # 在启用部分批次训练时使用的批次比例 (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13fdb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数声明\n",
    "\n",
    "class SettingPredictorRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, num_rnn_layers, num_categories):\n",
    "        super(SettingPredictorRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "        # 输入是 当前时间差 delta_t (1维) 和 combined_setting 的嵌入向量 (embedding_dim 维)\n",
    "        # 模型会根据当前时间差、设置和历史预测下一个时间步的时间差和设置\n",
    "        self.setting_embedding = nn.Embedding(num_categories, embedding_dim)\n",
    "        input_size = 1 + embedding_dim\n",
    "\n",
    "        # 使用 GRU 作为 RNN 层\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_rnn_layers, batch_first=True)\n",
    "\n",
    "        # 输出层\n",
    "        # 预测下一个时间步的时间差 delta_t (回归问题，输出 1维)\n",
    "        self.time_delta_output = nn.Linear(hidden_size, 1)\n",
    "        # 预测下一个 combined_setting (分类问题，输出 num_categories 维的 logits)\n",
    "        self.setting_output = nn.Linear(hidden_size, num_categories)\n",
    "\n",
    "    # 前向传播，处理填充后的批次序列\n",
    "    def forward(self, time_delta_seq, setting_seq, lengths, hidden_state=None):\n",
    "        # time_delta_seq 形状: (batch_size, seq_len) - 填充后的 当前时间差 序列\n",
    "        # setting_seq 形状: (batch_size, seq_len) - 填充后的 当前 setting 整数索引序列 (long tensor)\n",
    "        # lengths: 原始输入序列长度的列表或 tensor (对应 time_delta_seq 和 setting_seq 的长度)\n",
    "\n",
    "        # 将 setting 整数索引转换为嵌入向量\n",
    "        setting_embedded = self.setting_embedding(setting_seq) # 形状: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # 组合当前时间差输入和嵌入后的 setting\n",
    "        input_seq = torch.cat((time_delta_seq.unsqueeze(-1), setting_embedded), dim=-1) # 形状: (batch_size, seq_len, 1 + embedding_dim)\n",
    "\n",
    "        # 打包填充后的序列\n",
    "        # lengths 必须在 CPU 上\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # 通过 RNN 层\n",
    "        packed_output, hidden_state = self.rnn(packed_input, hidden_state)\n",
    "\n",
    "        # 将打包的序列重新填充回原始形状\n",
    "        output_seq, _ = rnn_utils.pad_packed_sequence(packed_output, batch_first=True, total_length=input_seq.size(1)) # 形状: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # 通过输出层进行预测\n",
    "        # 预测的是下一个时间步的 delta_t (即输入序列中当前步对应的下一个 delta_t)\n",
    "        predicted_next_delta_t = self.time_delta_output(output_seq) # 形状: (batch_size, seq_len, 1)\n",
    "        # 预测的是下一个 setting 的 logits (即输入序列中当前步对应的下一个 setting)\n",
    "        predicted_next_setting_logits = self.setting_output(output_seq) # 形状: (batch_size, seq_len, num_categories)\n",
    "\n",
    "        # 压缩 predicted_next_delta_t 的最后一维\n",
    "        predicted_next_delta_t = predicted_next_delta_t.squeeze(-1) # 形状: (batch_size, seq_len)\n",
    "\n",
    "        return predicted_next_delta_t, predicted_next_setting_logits, hidden_state\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. 准备数据加载器 SequenceDataset 和 Collate Function (在 collate_fn 中计算 delta_t 输入和目标)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        自定义数据集类。\n",
    "        Args:\n",
    "            data_list: DataFrame 列表，每个 DataFrame 代表一个序列。\n",
    "                       DataFrame 应包含 'time' (float) 和\n",
    "                       'combined_setting' (类别类型，类别为 0-124 的整数) 列。\n",
    "                       注意：time 到 delta_t 的转换在 collate_fn 中完成。\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = self.data_list[idx]\n",
    "        # 将整个 'time' 和 'combined_setting' 序列返回\n",
    "        time_seq = torch.FloatTensor(df['time'].values)\n",
    "        setting_seq = torch.LongTensor(df['combined_setting'].astype(int).values) # 确保是 LongTensor 用于 embedding\n",
    "\n",
    "        # 返回完整序列数据和原始长度\n",
    "        return time_seq, setting_seq, len(df)\n",
    "\n",
    "# 批处理数据的 Collate Function\n",
    "def collate_fn(batch):\n",
    "    # batch 是一个元组列表：[(time_seq_1, setting_seq_1, len_1), ...]\n",
    "\n",
    "    # 根据原始序列长度降序排序批次\n",
    "    batch.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # 解压批次数据\n",
    "    time_seqs_list, setting_seqs_list, original_lengths = zip(*batch)\n",
    "\n",
    "    # 过滤掉原始长度小于 3 的序列，这些序列无法构建有效的输入和目标序列 (长度 original_length - 2)\n",
    "    valid_indices = [i for i, length in enumerate(original_lengths) if length >= 3]\n",
    "\n",
    "    if not valid_indices:\n",
    "        # 如果批次中没有长度 >= 3 的序列，返回 None 表示空批次\n",
    "        return None\n",
    "\n",
    "    # 提取有效的序列和长度\n",
    "    time_seqs_list = [time_seqs_list[i] for i in valid_indices]\n",
    "    setting_seqs_list = [setting_seqs_list[i] for i in valid_indices]\n",
    "    valid_original_lengths = [original_lengths[i] for i in valid_indices]\n",
    "\n",
    "\n",
    "    # --- 计算输入序列 (当前 delta_t 和 setting) 和目标序列 (下一个 delta_t 和 setting) ---\n",
    "    # 它们都对应原始序列长度 - 2 的部分\n",
    "\n",
    "    # delta_t 输入: time[i+1] - time[i] for i from 0 to original_length - 3\n",
    "    delta_t_inputs_list = [(seq[1:-1] - seq[:-2]) for seq in time_seqs_list]\n",
    "    # setting 输入: setting[i] for i from 0 to original_length - 3\n",
    "    setting_inputs_list = [seq[:-2] for seq in setting_seqs_list]\n",
    "\n",
    "    # delta_t 目标: time[i+2] - time[i+1] for i from 0 to original_length - 3\n",
    "    delta_t_targets_list = [(seq[2:] - seq[1:-1]) for seq in time_seqs_list]\n",
    "    # setting 目标: setting[i+1] for i from 0 to original_length - 3\n",
    "    setting_targets_list = [seq[1:-1] for seq in setting_seqs_list]\n",
    "\n",
    "\n",
    "    # 输入/目标序列的长度都等于 original_length - 2\n",
    "    input_lengths = [length - 2 for length in valid_original_lengths]\n",
    "\n",
    "\n",
    "    # 填充输入序列\n",
    "    delta_t_inputs_padded = rnn_utils.pad_sequence(delta_t_inputs_list, batch_first=True, padding_value=0.0)\n",
    "    setting_inputs_padded = rnn_utils.pad_sequence(setting_inputs_list, batch_first=True, padding_value=0)\n",
    "\n",
    "    # 填充目标序列\n",
    "    delta_t_targets_padded = rnn_utils.pad_sequence(delta_t_targets_list, batch_first=True, padding_value=0.0)\n",
    "    setting_targets_padded = rnn_utils.pad_sequence(setting_targets_list, batch_first=True, padding_value=0)\n",
    "\n",
    "\n",
    "    # 输入序列的有效长度\n",
    "    input_lengths_tensor = torch.LongTensor(input_lengths)\n",
    "\n",
    "    # 根据输入序列的有效长度重新排序批次\n",
    "    sorted_lengths, sorted_indices = torch.sort(input_lengths_tensor, descending=True)\n",
    "\n",
    "    # 按照 sorted_indices 对所有张量进行排序\n",
    "    delta_t_inputs_padded = delta_t_inputs_padded[sorted_indices]\n",
    "    setting_inputs_padded = setting_inputs_padded[sorted_indices]\n",
    "    delta_t_targets_padded = delta_t_targets_padded[sorted_indices]\n",
    "    setting_targets_padded = setting_targets_padded[sorted_indices]\n",
    "\n",
    "    # 将张量移动到设备\n",
    "    delta_t_inputs_padded = delta_t_inputs_padded.to(device)\n",
    "    setting_inputs_padded = setting_inputs_padded.to(device)\n",
    "    delta_t_targets_padded = delta_t_targets_padded.to(device)\n",
    "    setting_targets_padded = setting_targets_padded.to(device)\n",
    "    # sorted_lengths 保持在 CPU\n",
    "\n",
    "    # 返回 delta_t 输入, setting 输入, delta_t 目标, setting 目标, 输入长度\n",
    "    return delta_t_inputs_padded, setting_inputs_padded, delta_t_targets_padded, setting_targets_padded, sorted_lengths\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. 实现训练函数 train_model (使用 delta_t 目标计算时间预测损失)\n",
    "#    接收模型索引作为参数进行打印。\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def train_model(model, model_idx, dataloader, optimizer, time_criterion, setting_criterion, epochs, time_scaler,setting_scaler, iteration_num):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    total_batches = len(dataloader)\n",
    "    # 根据迭代次数决定使用的批次数量\n",
    "    if iteration_num < EARLY_ITER_BATCH_THRESHOLD:\n",
    "        batches_to_use = max(1, int(total_batches * EARLY_ITER_BATCH_PERCENT))\n",
    "    else:\n",
    "        batches_to_use = total_batches\n",
    "\n",
    "    # 使用 tqdm 显示 epoch 进度，使用传入的 model_idx\n",
    "    epoch_tqdm = tqdm(range(epochs), desc=f\"迭代 {iteration_num} (模型 {model_idx}) 训练\", leave=False)\n",
    "    for epoch in epoch_tqdm:\n",
    "        batch_count = 0\n",
    "        # 使用 tqdm 显示批次进度\n",
    "        batch_tqdm = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_data in batch_tqdm:\n",
    "            if batch_data is None: continue # 跳过空批次\n",
    "\n",
    "            # 从 collate_fn 获取批次数据\n",
    "            # 获取的是 delta_t 输入\n",
    "            delta_t_inputs, setting_inputs, delta_t_targets, setting_targets, lengths = batch_data\n",
    "\n",
    "            optimizer.zero_grad() # 清零梯度\n",
    "\n",
    "            # 前向传播\n",
    "            # 模型现在输出的是 predicted_next_delta_t 和 predicted_next_setting_logits\n",
    "            predicted_next_delta_t, predicted_next_setting_logits, _ = model(delta_t_inputs, setting_inputs, lengths)\n",
    "\n",
    "            # 计算损失\n",
    "            # predicted_next_delta_t 形状: (batch_size, seq_len)\n",
    "            # delta_t_targets 形状: (batch_size, seq_len)\n",
    "            time_loss = time_criterion(predicted_next_delta_t, delta_t_targets)\n",
    "\n",
    "            # predicted_next_setting_logits 形状: (batch_size, seq_len, num_categories)\n",
    "            # setting_targets 形状: (batch_size, seq_len)\n",
    "            # 需要调整 logits 的维度到 (batch_size, num_categories, seq_len)\n",
    "            setting_loss = setting_criterion(predicted_next_setting_logits.permute(0, 2, 1), setting_targets)\n",
    "\n",
    "            # 计算总损失，并应用时间损失缩放因子\n",
    "            loss = time_loss * time_scaler + setting_loss*setting_scaler\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            # 可选：梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_count += 1\n",
    "            # 在早期迭代中，只训练部分批次\n",
    "            if batch_count >= batches_to_use:\n",
    "                 break\n",
    "\n",
    "            # 更新批次进度条的后缀信息（可选）\n",
    "            batch_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 更新 epoch 进度条的后缀信息（可选）\n",
    "        # 注意：这里显示的是最后一个批次的损失，不是平均损失\n",
    "        epoch_tqdm.set_postfix(last_batch_loss=loss.item())\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. 实现评估函数 evaluate_sequence_loss (计算单个序列 **平均** 损失)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_sequence_loss(model, time_seq_full, setting_seq_full, time_criterion, setting_criterion, time_scaler,setting_scaler):\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "\n",
    "        seq_len = time_seq_full.size(0)\n",
    "        # 序列长度小于 3 无法构建输入和目标序列 (长度 original_length - 2)\n",
    "        if seq_len < 3:\n",
    "            # 返回无穷大，表示无法计算有效损失，在比较时会被排除\n",
    "            return float('inf')\n",
    "\n",
    "        # --- 构建输入序列 (当前 delta_t 和 setting) 和目标序列 (下一个 delta_t 和 setting) ---\n",
    "        # 它们都对应原始序列长度 - 2 的部分\n",
    "\n",
    "        # delta_t 输入: time[i+1] - time[i] for i from 0 to seq_len - 3\n",
    "        delta_t_inputs_sliced = (time_seq_full[1:-1] - time_seq_full[:-2]).unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "        # setting 输入: setting[i] for i from 0 to seq_len - 3\n",
    "        setting_inputs_sliced = setting_seq_full[:-2].unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "\n",
    "        # delta_t 目标: time[i+2] - time[i+1] for i from 0 to seq_len - 3\n",
    "        delta_t_targets_sliced = (time_seq_full[2:] - time_seq_full[1:-1]).unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "        # setting 目标: setting[i+1] for i from 0 to seq_len - 3\n",
    "        setting_targets_sliced = setting_seq_full[1:-1].unsqueeze(0).to(device) # 形状: (1, seq_len - 2)\n",
    "\n",
    "        # 输入序列的实际长度\n",
    "        eval_input_len = seq_len - 2 # 有效的预测步数\n",
    "        lengths = torch.tensor([eval_input_len]) # 保持在 CPU\n",
    "\n",
    "        # 前向传播，计算整个序列的预测结果 (长度为 eval_input_len)\n",
    "        predicted_next_delta_t, predicted_next_setting_logits, _ = model(delta_t_inputs_sliced, setting_inputs_sliced, lengths)\n",
    "\n",
    "        # 计算整个序列的损失 (注意：损失函数如 MSELoss 和 CrossEntropyLoss 默认计算的是批次和序列长度上的平均)\n",
    "        # 但在这里我们处理的是单个序列 (batch_size = 1)，并且使用了 pack_padded_sequence，\n",
    "        # PyTorch 会确保损失计算只在有效长度上进行。\n",
    "        # 所以 time_criterion(predicted_next_delta_t, delta_t_targets_sliced) 计算的是 batch 和 有效长度上的平均损失。\n",
    "        # setting_criterion(...) 也类似。\n",
    "\n",
    "        time_loss = time_criterion(predicted_next_delta_t, delta_t_targets_sliced)\n",
    "        setting_loss = setting_criterion(predicted_next_setting_logits.permute(0, 2, 1), setting_targets_sliced)\n",
    "\n",
    "        # 计算总损失 (按步加权平均)\n",
    "        total_loss_per_step = time_loss * time_scaler + setting_loss\n",
    "\n",
    "        # total_loss_per_step 现在已经是每个预测步的平均损失了 (因为 MSELoss/CrossEntropyLoss 默认对 batch 和序列长度取平均)\n",
    "        # 但是 pack_padded_sequence 的行为可能会影响这个平均，为了安全和明确，我们还是按总损失再除以步数\n",
    "        # 更稳妥的方法是使用 reduction='sum' 然后手动除以有效步数\n",
    "        time_criterion_sum = nn.MSELoss(reduction='sum')\n",
    "        setting_criterion_sum = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        time_loss_sum = time_criterion_sum(predicted_next_delta_t, delta_t_targets_sliced)\n",
    "        setting_loss_sum = setting_criterion_sum(predicted_next_setting_logits.permute(0, 2, 1), setting_targets_sliced)\n",
    "\n",
    "        total_sum_loss = time_loss_sum * time_scaler + setting_loss_sum * setting_scaler\n",
    "    \n",
    "        # 计算 **平均** 损失：总和损失除以有效预测步数\n",
    "        average_loss_per_step = total_sum_loss / eval_input_len\n",
    "        average_set_loss_per_step = setting_loss_sum / eval_input_len\n",
    "\n",
    "\n",
    "        # 返回标量平均损失值\n",
    "        return average_loss_per_step.item(),average_set_loss_per_step.item()\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5. 实现 EM-like 聚类算法 run_rnn_clustering (加入干扰项处理)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def run_rnn_clustering(transformed_list, num_main_models, embedding_dim, hidden_size, num_rnn_layers,\n",
    "                       num_categories, time_scaler,setting_scaler, total_iterations, convergence_threshold,\n",
    "                       epoch_schedule, batch_size, early_iter_batch_threshold, early_iter_batch_percent,\n",
    "                       interference_cluster_label, interference_detection_start_iter, high_avg_loss_threshold, num_rand_sequences):\n",
    "\n",
    "    total_sequences = len(transformed_list)\n",
    "    print(f\"开始基于 RNN 的聚类，共有 {total_sequences} 条序列，聚成 {num_main_models} 类 + 1 干扰类 ({interference_cluster_label})。\")\n",
    "\n",
    "    # 1. 初始化\n",
    "    # 创建 NUM_MAIN_MODELS 个结构相同的 RNN 模型\n",
    "    models = [SettingPredictorRNN(embedding_dim, hidden_size, num_rnn_layers, num_categories).to(device) for _ in range(num_main_models)]\n",
    "\n",
    "    # current_assignments: 存储当前迭代中用于 M 步训练和 E 步重新分配的簇分配 (0, 1, 2, 或 interference_cluster_label)。\n",
    "    # 初始化时，所有序列随机分配到主簇。长度不足 3 的序列暂时分配到 -1。\n",
    "    current_assignments = np.full(total_sequences, -1, dtype=int) # 初始化为 -1\n",
    "    # 先将长度 >= 3 的序列随机分配到主簇\n",
    "    long_enough_indices = np.where(np.array([len(item[0]) for item in transformed_list]) >= 3)[0]\n",
    "    current_assignments[long_enough_indices] = np.random.randint(0, num_main_models, len(long_enough_indices))\n",
    "\n",
    "\n",
    "    print(f\"初始随机分配到主簇 (长度>=3 的序列): {np.bincount(current_assignments[current_assignments != -1], minlength=num_main_models)}\")\n",
    "    print(f\"初始未分配序列 (长度<3): {np.sum(current_assignments == -1)}\")\n",
    "\n",
    "\n",
    "    # 定义损失函数 (用于 E 步计算单序列损失，使用 reduction='sum')\n",
    "    time_criterion_sum = nn.MSELoss(reduction='sum')\n",
    "    setting_criterion_sum = nn.CrossEntropyLoss(reduction='sum')\n",
    "    # 定义损失函数 (用于 M 步训练批次，使用默认 reduction='mean')\n",
    "    time_criterion_mean = nn.MSELoss()\n",
    "    setting_criterion_mean = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # 记录被标记为干扰项的序列的原始索引 (仅用于跟踪和最终返回)\n",
    "    removed_interference_indices_tracker = []\n",
    "\n",
    "    # 2. EM-like 迭代循环\n",
    "    main_tqdm = tqdm(range(total_iterations), desc=\"EM 迭代总进度\")\n",
    "    for iter_num in main_tqdm:\n",
    "        main_tqdm.set_description(f\"EM 迭代 {iter_num + 1}/{total_iterations}\")\n",
    "\n",
    "        # prev_assignments: 记录本轮迭代 E 步开始前 current_assignments 的状态，用于收敛检查 (仅检查主簇变化)\n",
    "        prev_assignments = current_assignments.copy()\n",
    "\n",
    "        # active_indices: 获取当前仍在参与聚类的主簇序列的原始索引 (即 current_assignments != interference_cluster_label 的序列)\n",
    "        active_indices_mask = (current_assignments != interference_cluster_label) & (current_assignments != -1) # 排除已标记为干扰项和尚未初始分配的 (-1)\n",
    "        active_indices = np.where(active_indices_mask)[0]\n",
    "        current_total_active_sequences = len(active_indices)\n",
    "\n",
    "\n",
    "        # 只有当还有活跃序列时才进行 M 步训练\n",
    "        if current_total_active_sequences > 0:\n",
    "             print(f\"\\n--- 迭代 {iter_num + 1}: M 步 (训练模型)，当前活跃序列数: {current_total_active_sequences} ---\")\n",
    "             # 获取本轮迭代应训练的 epochs 数量\n",
    "             current_epochs = epoch_schedule[min(iter_num, len(epoch_schedule) - 1)]\n",
    "\n",
    "             # M 步: 根据 current_assignments 训练每个模型 (仅使用活跃序列)\n",
    "             for model_idx in range(num_main_models):\n",
    "                 # 找到当前分配给该模型的所有 *活跃* 序列的原始索引\n",
    "                 assigned_indices_in_active = active_indices[current_assignments[active_indices] == model_idx]\n",
    "\n",
    "                 if len(assigned_indices_in_active) == 0:\n",
    "                     print(f\"  模型 {model_idx} 没有活跃序列分配到，跳过训练。\")\n",
    "                     continue\n",
    "\n",
    "                 # 获取这些索引对应的原始数据框\n",
    "                 # Dataset 会只加载这些索引对应的 df\n",
    "                 assigned_dataset = SequenceDataset([transformed_list[i][0] for i in assigned_indices_in_active])\n",
    "                 # collate_fn 将过滤掉长度不足 3 的序列，DataLoader 会处理批次和填充\n",
    "                 assigned_dataloader = DataLoader(assigned_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "                 # 只有当 DataLoader 不为空时才训练 (即存在长度 >= 3 的序列)\n",
    "                 if len(assigned_dataloader) > 0:\n",
    "                    # 为当前模型创建一个优化器\n",
    "                    optimizer = optim.Adam(models[model_idx].parameters())\n",
    "\n",
    "                    # 调用训练函数训练当前模型，传入模型索引，使用 mean reduction 的损失函数\n",
    "                    train_model(models[model_idx], model_idx, assigned_dataloader, optimizer,\n",
    "                                time_criterion_mean, setting_criterion_mean, current_epochs,\n",
    "                                time_scaler, setting_scaler,iter_num)\n",
    "                 else:\n",
    "                     print(f\"  模型 {model_idx} 分配到的活跃序列中没有长度 >= 3 的，跳过训练。\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n--- 迭代 {iter_num + 1}: M 步 (训练模型)，当前没有活跃序列，跳过训练。---\")\n",
    "            # 如果没有活跃序列，且不是第一轮，可能已经收敛或所有都被标记为干扰项\n",
    "            if iter_num > 0:\n",
    "                 print(\"\\n没有活跃序列，且不是第一轮迭代，可能已收敛。\")\n",
    "                 break # 跳出循环\n",
    "\n",
    "\n",
    "        print(f\"\\n--- 迭代 {iter_num + 1}: E 步 (重分配序列及干扰项检测) ---\")\n",
    "\n",
    "        # 在 E 步开始时，找出所有未被最终标记为干扰项的序列 (可能包含长度不足 3 的)\n",
    "        # 这些是 candidates for re-assignment or interference detection\n",
    "        candidate_indices_mask = (current_assignments != interference_cluster_label) # 只要不是干扰项，都是候选\n",
    "        candidate_indices = np.where(candidate_indices_mask)[0]\n",
    "        current_total_candidates = len(candidate_indices)\n",
    "\n",
    "        if current_total_candidates == 0:\n",
    "             print(\"  当前没有候选序列需要评估 (所有序列都已标记为干扰项)。\")\n",
    "             break # 跳出循环\n",
    "\n",
    "        # 计算所有 *候选* 序列在所有主模型上的损失 (使用 sum reduction 的损失函数)\n",
    "        # losses_for_candidates 形状: (当前候选序列总数, 主模型总数)\n",
    "        losses_for_candidates = np.full((current_total_candidates, num_main_models), float('inf')) # 初始化为无穷大\n",
    "        set_losses_for_candidates = np.full((current_total_candidates, num_main_models), float('inf'))\n",
    "        print(f\"  计算 {current_total_candidates} 条候选序列在每个模型上的平均损失...\")\n",
    "        eval_tqdm = tqdm(range(current_total_candidates), desc=\"计算损失\", leave=False)\n",
    "        for j in eval_tqdm:\n",
    "             original_idx = candidate_indices[j] # 获取对应的原始索引\n",
    "             df = transformed_list[original_idx][0] # 获取数据框\n",
    "\n",
    "             time_seq_full = torch.FloatTensor(df['time'].values)\n",
    "             setting_seq_full = torch.LongTensor(df['combined_setting'].astype(int).values)\n",
    "\n",
    "             # evaluate_sequence_loss 内部会检查长度是否 >= 3，并返回 inf 或平均损失\n",
    "             for model_idx in range(num_main_models):\n",
    "                 # evaluate_sequence_loss 现在返回的是平均损失\n",
    "                 avg_loss,set_loss = evaluate_sequence_loss(models[model_idx], time_seq_full, setting_seq_full,\n",
    "                                                   time_criterion_sum, setting_criterion_sum, time_scaler,setting_scaler)\n",
    "                 losses_for_candidates[j, model_idx],set_losses_for_candidates[j, model_idx] = avg_loss,set_loss # 记录平均损失\n",
    "\n",
    "        # --- 干扰项检测和移除 ---\n",
    "        # 在指定迭代轮次之后进行干扰项检测\n",
    "        if iter_num >= interference_detection_start_iter -1 :\n",
    "            print(\"  进行干扰项检测...\")\n",
    "            # 只考虑那些所有模型损失都不是无穷大的候选序列 (即长度 >= 3 的序列)\n",
    "            valid_loss_candidate_indices_relative = np.where(np.isfinite(losses_for_candidates).all(axis=1))[0]\n",
    "            # 对应的原始索引\n",
    "            valid_loss_candidates_original_indices = candidate_indices[valid_loss_candidate_indices_relative]\n",
    "            # 对应的平均损失矩阵 (只包含长度 >= 3 的序列)\n",
    "            valid_avg_losses = losses_for_candidates[valid_loss_candidate_indices_relative]\n",
    "            set_avg_losses = set_losses_for_candidates[valid_loss_candidate_indices_relative]\n",
    "\n",
    "            if len(valid_loss_candidate_indices_relative) > 0:\n",
    "                 # 计算这些序列在所有主模型上的 平均平均损失 (只是为了排序，不是必须的)\n",
    "                 min_of_avg_losses_valid_candidates = valid_avg_losses.var(axis=1)#改：应该计算所有主模型中的最低损失而非平均损失\n",
    "\n",
    "                 # 识别 平均损失 的 平均值 高于阈值的有效损失候选序列的索引 (在 valid_loss_candidate_indices_relative 中的相对索引)\n",
    "                 high_avg_loss_valid_candidate_indices_relative_to_valid = np.where(min_of_avg_losses_valid_candidates > high_avg_loss_threshold)[0]\n",
    "\n",
    "                 # 将这些高平均损失有效候选序列的相对索引映射回原始索引\n",
    "                 high_avg_loss_candidates_original_indices = valid_loss_candidates_original_indices[high_avg_loss_valid_candidate_indices_relative_to_valid]\n",
    "\n",
    "\n",
    "                 # 从高平均损失候选者中，选取平均损失最高的序列作为干扰项\n",
    "                 # 确保不超过已知干扰项总数 (num_rand_sequences)，并且不重复移除\n",
    "                 # 找到尚未被标记为干扰项的高平均损失候选者\n",
    "                 currently_not_removed_high_avg_loss_mask = np.isin(high_avg_loss_candidates_original_indices, removed_interference_indices_tracker, invert=True)\n",
    "                 currently_not_removed_high_avg_loss_original_indices = high_avg_loss_candidates_original_indices[currently_not_removed_high_avg_loss_mask]\n",
    "\n",
    "                 # 对这些尚未被移除的高平均损失序列，按平均损失的平均值降序排序\n",
    "                 # 需要获取这些序列在 min_of_avg_losses_valid_candidates 中的对应值\n",
    "                 # 找到 currently_not_removed_high_avg_loss_original_indices 在 valid_loss_candidates_original_indices 中的相对索引\n",
    "                 relative_indices_in_valid_for_candidates_to_sort = np.where(np.isin(valid_loss_candidates_original_indices, currently_not_removed_high_avg_loss_original_indices))[0]\n",
    "                 min_of_avg_losses_for_sorting = min_of_avg_losses_valid_candidates[relative_indices_in_valid_for_candidates_to_sort]\n",
    "                 # 对原始索引进行排序，基于其对应的平均损失的平均值\n",
    "                 #sorted_candidates_original_indices = currently_not_removed_high_avg_loss_original_indices[np.argsort(min_of_avg_losses_for_sorting)[::-1]]\n",
    "                 sorted_candidates_original_indices = currently_not_removed_high_avg_loss_original_indices[np.argsort(min_of_avg_losses_for_sorting) ]\n",
    "\n",
    "             \n",
    "                 # 选取前 N 个作为本轮被标记为干扰项的序列\n",
    "                 num_to_select_this_iter = min(len(sorted_candidates_original_indices), num_rand_sequences - len(removed_interference_indices_tracker),20)\n",
    "                 indices_to_remove_this_iter_original = sorted_candidates_original_indices[:num_to_select_this_iter]#每轮最多标记20个\n",
    "\n",
    "                 # 将这些序列标记为干扰项 (在 current_assignments 中设置为干扰簇标签)\n",
    "                 current_assignments[indices_to_remove_this_iter_original] = interference_cluster_label\n",
    "                 # 添加到已移除列表中 (跟踪用)\n",
    "                 removed_interference_indices_tracker.extend(indices_to_remove_this_iter_original)\n",
    "                 removed_count_this_iter = len(indices_to_remove_this_iter_original)\n",
    "                 print(f\"  本轮标记 {removed_count_this_iter} 条序列为干扰项。总计已标记 {len(removed_interference_indices_tracker)} 条。\")\n",
    "            else:\n",
    "                 print(\"  没有符合高平均损失阈值的候选序列 (长度 >= 3)，本轮未标记新的干扰项。\")\n",
    "        else:\n",
    "            print(\"  干扰项检测尚未开始。\")\n",
    "\n",
    "\n",
    "        # --- 主簇重新分配 ---\n",
    "        # 找到当前仍未被标记为干扰项的序列 (这些是需要重新分配到主簇或保持主簇分配的序列)\n",
    "        remaining_main_cluster_candidate_indices_mask = (current_assignments != interference_cluster_label) # 修复：只要不是干扰项，都是候选\n",
    "        remaining_main_cluster_candidate_indices = np.where(remaining_main_cluster_candidate_indices_mask)[0]\n",
    "\n",
    "\n",
    "        # 从 losses_for_candidates 中，提取出这些剩余主簇候选序列的损失\n",
    "        # losses_for_candidates 的行是按照 E 步开始时的 candidate_indices 的顺序排列的\n",
    "        # 找到 remaining_main_cluster_candidate_indices 在 E 步开始时的 candidate_indices 中的位置 (相对索引)\n",
    "        relative_indices_in_candidates_for_remaining = np.where(np.isin(candidate_indices, remaining_main_cluster_candidate_indices))[0]\n",
    "        losses_for_remaining_main_candidates = losses_for_candidates[relative_indices_in_candidates_for_remaining]\n",
    "\n",
    "        # 只对那些有有效平均损失的序列 (长度 >= 3) 进行重新分配 (排除 inf)\n",
    "        valid_loss_remaining_mask = np.isfinite(losses_for_remaining_main_candidates).all(axis=1)\n",
    "        valid_loss_remaining_relative_indices_in_candidates = relative_indices_in_candidates_for_remaining[valid_loss_remaining_mask]\n",
    "        valid_loss_remaining_original_indices = candidate_indices[valid_loss_remaining_relative_indices_in_candidates] # 这些是需要重新分配的序列的原始索引\n",
    "\n",
    "\n",
    "        if len(valid_loss_remaining_original_indices) > 0:\n",
    "             # 找到这些序列在三个主模型上的 **平均损失** 最小的模型索引 (0, 1, 或 2)\n",
    "             losses_for_valid_remaining = losses_for_candidates[valid_loss_remaining_relative_indices_in_candidates]\n",
    "             new_main_assignments_for_valid_remaining = losses_for_valid_remaining.argmin(axis=1)\n",
    "\n",
    "             # 更新这些序列在 current_assignments 中的分组 (设置为 0, 1, 或 2)\n",
    "             current_assignments[valid_loss_remaining_original_indices] = new_main_assignments_for_valid_remaining\n",
    "\n",
    "             print(f\"  {len(valid_loss_remaining_original_indices)} 条长度 >= 3 的序列被重新分配到主簇。\")\n",
    "\n",
    "        else:\n",
    "             print(\"  没有长度 >= 3 的序列需要重新分配到主簇。\")\n",
    "\n",
    "\n",
    "        # 检查收敛性：比较本轮迭代 E 步开始前和结束后的 current_assignments (仅考虑主簇)\n",
    "        # 找到在两轮迭代中都未被标记为干扰项的序列的原始索引\n",
    "        stable_indices_mask = (prev_assignments != interference_cluster_label) & (current_assignments != interference_cluster_label) & (prev_assignments != -1) & (current_assignments != -1) # 修复：排除-1的序列\n",
    "        stable_indices = np.where(stable_indices_mask)[0]\n",
    "\n",
    "        if len(stable_indices) > 0:\n",
    "            # 比较这些稳定序列在两轮迭代中的主簇分配\n",
    "            prev_main_assignments_stable = prev_assignments[stable_indices]\n",
    "            current_main_assignments_stable = current_assignments[stable_indices]\n",
    "\n",
    "            # 计算改变主簇分配的序列数量 (仅在稳定序列中)\n",
    "            num_changes = np.sum(prev_main_assignments_stable != current_main_assignments_stable)\n",
    "            # 计算改变分组的序列比例 (基于总序列数)\n",
    "            change_percent = num_changes / total_sequences\n",
    "\n",
    "            print(f\"  未被标记干扰项且已分配到主簇的序列中，有 {num_changes} 条改变了主簇 ({change_percent:.2%})。\")\n",
    "\n",
    "            # 判断是否收敛：如果改变比例低于阈值，且不是第一轮迭代 (iter_num > 0)\n",
    "            if change_percent < convergence_threshold and iter_num > 0:\n",
    "                print(f\"收敛达成。总分组改变比例 ({change_percent:.2%}) 低于阈值 ({convergence_threshold:.2%})。\")\n",
    "                break\n",
    "        elif iter_num > 0: # 如果没有稳定序列，且不是第一轮\n",
    "             print(\"  没有稳定序列 (未被标记干扰项且已分配到主簇)，无法计算收敛率。\")\n",
    "             pass # 继续迭代或添加其他条件\n",
    "\n",
    "        else: # 第一轮迭代结束，没有上一轮状态进行比较\n",
    "             print(\"  第一轮迭代结束，无法计算收敛率。\")\n",
    "\n",
    "\n",
    "        # 打印当前的分组统计 (包含干扰项和未分配的 -1)\n",
    "        print(f\"  当前分组统计: {np.bincount(current_assignments + 1, minlength=num_main_models + 2)}\") # +1 让 -1 变为 0，0 变为 1 等，minlength 确保包含所有可能的类别\n",
    "        print(f\"    (-1: {np.sum(current_assignments == -1)}, 0-{num_main_models-1}: {np.bincount(current_assignments[current_assignments >= 0], minlength=num_main_models)[:num_main_models]}, {interference_cluster_label}: {np.sum(current_assignments == interference_cluster_label)})\")\n",
    "\n",
    "\n",
    "        # 如果达到最大迭代次数\n",
    "        if iter_num == total_iterations - 1:\n",
    "             print(\"达到最大迭代次数。\")\n",
    "\n",
    "        main_tqdm.update(0) # 更新主进度条显示的信息 (主要是当前迭代数)\n",
    "\n",
    "    # 迭代结束\n",
    "    # 将最终的 current_assignments 赋值给 final_assignments\n",
    "    final_assignments = current_assignments.copy()\n",
    "\n",
    "    # 将剩余未分配的序列 (-1) 也标记为干扰项\n",
    "    remaining_unassigned_indices = np.where(final_assignments == -1)[0]\n",
    "    if len(remaining_unassigned_indices) > 0:\n",
    "        print(f\"迭代结束，将剩余 {len(remaining_unassigned_indices)} 条未分配序列标记为干扰项。\")\n",
    "        final_assignments[remaining_unassigned_indices] = interference_cluster_label\n",
    "        # 添加到最终跟踪列表中\n",
    "        # 修复：只添加尚未被标记为干扰项的未分配序列\n",
    "        already_removed_mask = np.isin(remaining_unassigned_indices, removed_interference_indices_tracker)\n",
    "        newly_removed_indices = remaining_unassigned_indices[~already_removed_mask]\n",
    "        removed_interference_indices_tracker.extend(newly_removed_indices)\n",
    "\n",
    "\n",
    "    print(\"\\n--- 聚类完成 ---\")\n",
    "    # 最终分组统计 (包含干扰项)\n",
    "    assigned_indices_mask = final_assignments != -1\n",
    "    if assigned_indices_mask.sum() > 0:\n",
    "        final_clusters_counts = np.bincount(final_assignments[assigned_indices_mask], minlength=num_main_models + 1)\n",
    "        print(f\"最终各簇包含的序列数量 (0-{num_main_models-1} 是主簇, {interference_cluster_label} 是干扰簇):\")\n",
    "        print(f\"簇 0-{num_main_models-1}: {final_clusters_counts[:num_main_models]}, 干扰项 ({interference_cluster_label}): {final_clusters_counts[interference_cluster_label] if interference_cluster_label < len(final_clusters_counts) else 0}\")\n",
    "    else:\n",
    "        print(\"最终所有序列都未被分配到任何簇。\")\n",
    "\n",
    "\n",
    "    return models, final_assignments, removed_interference_indices_tracker # 返回 models\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6. 聚类结果可视化函数 (包含干扰项类别)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def visualize_clustering_results(transformed_list, final_assignments, num_main_models, interference_cluster_label):\n",
    "    \"\"\"\n",
    "    可视化聚类结果，显示原始标签与分配到的簇之间的交叉关系 (包含干扰项类别)。\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 聚类结果可视化 ---\")\n",
    "\n",
    "    original_labels = [item[1] for item in transformed_list] # 提取所有原始标签\n",
    "    # 根据最终分组创建分组标签 (0, 1, 2 对应主簇，干扰簇使用单独标签)\n",
    "    assignment_labels = [f\"簇_{a}\" if a != interference_cluster_label else \"干扰项\" for a in final_assignments]\n",
    "\n",
    "    # 创建原始标签和分配簇的 DataFrame\n",
    "    results_df = pd.DataFrame({'原始标签': original_labels, '分配到的簇': assignment_labels})\n",
    "\n",
    "    # 确保交叉表中包含所有可能的原始标签和所有可能的分配簇标签\n",
    "    all_original_labels = sorted(list(set(original_labels))) # 包含 onestep, repeat, reset, rand\n",
    "    all_assignment_labels = [f\"簇_{i}\" for i in range(num_main_models)] + [\"干扰项\"]\n",
    "    # 确保 '干扰项' 标签在分配簇中存在，即使没有序列被分到，以便reindex不出错\n",
    "    if \"干扰项\" not in all_assignment_labels:\n",
    "         all_assignment_labels.append(\"干扰项\")\n",
    "    # 按照簇号排序主簇标签，干扰项放最后\n",
    "    all_assignment_labels = sorted(all_assignment_labels, key=lambda x: int(x.split('_')[1]) if x.startswith('簇_') else 999)\n",
    "\n",
    "\n",
    "    # 计算交叉表\n",
    "    # .reindex 确保行和列按照指定的顺序和名称显示，没有的填 0\n",
    "    crosstab_df = pd.crosstab(results_df['原始标签'], results_df['分配到的簇']).reindex(index=all_original_labels, columns=all_assignment_labels, fill_value=0)\n",
    "\n",
    "    print(\"\\n原始标签与分配到的簇的交叉表:\")\n",
    "    print(crosstab_df)\n",
    "\n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(10, 7)) # 调整图大小以容纳更多标签\n",
    "    sns.heatmap(crosstab_df, annot=True, fmt='d', cmap='Blues', linewidths=.5)\n",
    "    plt.title('原始标签与分配到的簇的交叉表', fontsize=14)\n",
    "    plt.xlabel('分配到的簇', fontsize=12)\n",
    "    plt.ylabel('原始标签', fontsize=12)\n",
    "    plt.tight_layout() # 自动调整布局，防止标签重叠\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7. 单样本步进式预测函数及可视化 (仅针对非干扰项)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def predict_sequence_step_by_step(model, dataframe, num_categories):\n",
    "    \"\"\"\n",
    "    使用模型对单个序列进行步进式预测，并返回实际值和预测值。\n",
    "    预测的输入是当前 delta_t 和 setting，预测下一个 delta_t 和 setting。\n",
    "    实际预测时间需要根据实际时间进行累加。\n",
    "\n",
    "    Args:\n",
    "        model: 训练好的 RNN 模型。\n",
    "        dataframe: 单个序列的 DataFrame，包含 'time' (绝对时间) 和 'combined_setting' 列。\n",
    "        num_categories: setting 的总类别数 (125)。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (actual_time_sliced, predicted_time_abs, actual_setting_sliced, predicted_setting)\n",
    "               actual_time_sliced: 实际的时间序列 (从原始序列索引 1 开始) (numpy array)\n",
    "               predicted_time_abs: 预测的绝对时间序列 (从原始序列索引 1 开始) (numpy array)\n",
    "               actual_setting_sliced: 实际的设置序列 (从原始序列索引 1 开始) (numpy array, 整数 0-124)\n",
    "               predicted_setting: 预测的设置序列 (从原始序列索引 1 开始) (numpy array, 整数 0-124)\n",
    "               注意：预测序列和切片的实际序列长度是 seq_len - 1。\n",
    "               如果无法预测 (序列太短)，返回 None, None, None, None。\n",
    "    \"\"\"\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "\n",
    "        # 确保 dataframe 长度足够进行预测 (至少需要 2 步才能计算第一个 delta_t 并预测下一步)\n",
    "        seq_len = len(dataframe)\n",
    "        if seq_len < 2: # 修复：预测一步需要至少 2个点\n",
    "            return None, None, None, None\n",
    "\n",
    "        # 提取实际序列值\n",
    "        actual_time = dataframe['time'].values.astype(np.float32)\n",
    "        actual_setting = dataframe['combined_setting'].astype(int).values.astype(np.int64) # 确保是整数类型\n",
    "\n",
    "        # 初始化存储预测结果的列表\n",
    "        predicted_delta_t_list = []\n",
    "        predicted_setting_list = []\n",
    "\n",
    "        # 初始化 RNN 的隐藏状态\n",
    "        hidden_state = None # GRU 的隐藏状态可以是 None\n",
    "\n",
    "        # 步进式预测循环：\n",
    "        # 循环遍历实际序列，从第一个时间步 (索引 i=0) 作为模型的输入起点\n",
    "        # 输入到模型的是 actual_time[i+1]-actual_time[i] (delta_t 输入) 和 actual_setting[i] (setting 输入)\n",
    "        # 预测的是 actual_time[i+2]-actual_time[i+1] (预测 delta_t) 和 actual_setting[i+1] (预测 setting)\n",
    "        # 循环范围是 i 从 0 到 seq_len - 2 (共 seq_len - 1 步预测)\n",
    "        # 第 i 步的输入：actual_time[i+1]-actual_time[i] 和 actual_setting[i]\n",
    "        # 预测输出对应实际序列的索引 i+1 的时间差和设置\n",
    "\n",
    "        # 需要实际序列的前 seq_len - 1 个 delta_t 作为模型的输入序列\n",
    "        actual_delta_t_inputs_for_rnn = actual_time[1:] - actual_time[:-1] # 形状: (seq_len - 1)\n",
    "        # 需要实际序列的前 seq_len - 1 个 setting 作为模型的输入序列\n",
    "        actual_setting_inputs_for_rnn = actual_setting[:-1] # 形状: (seq_len - 1)\n",
    "\n",
    "        # 模型输入序列长度\n",
    "        rnn_input_len = seq_len - 1\n",
    "\n",
    "        # 将整个输入序列一次性输入到模型中，获取所有预测结果\n",
    "        # 这是模拟 RNN 的序列处理，而不是真正的单步循环预测\n",
    "        # 如果想做真正的单步预测，需要循环并手动管理 hidden_state\n",
    "        # 为了可视化对比所有步的预测，一次性输入更方便\n",
    "\n",
    "        # 准备输入张量 (增加批次维)\n",
    "        delta_t_inputs_tensor = torch.tensor(actual_delta_t_inputs_for_rnn, dtype=torch.float32).unsqueeze(0).to(device) # Shape: (1, seq_len - 1)\n",
    "        setting_inputs_tensor = torch.tensor(actual_setting_inputs_for_rnn, dtype=torch.long).unsqueeze(0).to(device) # Shape: (1, seq_len - 1)\n",
    "\n",
    "        # 准备 lengths tensor\n",
    "        lengths_tensor = torch.tensor([rnn_input_len]) # 保持在 CPU\n",
    "\n",
    "        # 将隐藏状态移动到设备\n",
    "        hidden_state = hidden_state.to(device) if hidden_state is not None else None\n",
    "\n",
    "        # 通过 RNN 进行前向传播\n",
    "        # 模型输出的是 predicted_next_delta_t 和 predicted_next_setting_logits\n",
    "        # predicted_next_delta_t 形状: (1, rnn_input_len)\n",
    "        # predicted_next_setting_logits 形状: (1, rnn_input_len, num_categories)\n",
    "        predicted_next_delta_t_seq, predicted_next_setting_logits_seq, _ = model(delta_t_inputs_tensor, setting_inputs_tensor, lengths_tensor, hidden_state)\n",
    "\n",
    "        # 转换为 numpy 数组\n",
    "        predicted_delta_t = predicted_next_delta_t_seq.squeeze(0).cpu().numpy() # Shape: (rnn_input_len,) = (seq_len - 1,)\n",
    "        predicted_setting = torch.argmax(predicted_next_setting_logits_seq.squeeze(0), dim=-1).cpu().numpy() # Shape: (rnn_input_len,) = (seq_len - 1,)\n",
    "\n",
    "        # 计算预测的绝对时间序列 (从 actual_time[1] 开始)\n",
    "        # predicted_time_abs[i] = actual_time[i] + predicted_delta_t[i] (i from 0 to seq_len-2)\n",
    "        predicted_time_abs = actual_time[:-1] + predicted_delta_t # Shape: (seq_len - 1)\n",
    "\n",
    "\n",
    "        # 实际的时间和设置序列需要截取到预测结果的长度一致 (从第二个元素开始)\n",
    "        # 预测序列长度是 seq_len - 1\n",
    "        # 它们预测的是 actual_time[1:] 的绝对时间和 actual_setting[1:] 的设置\n",
    "        actual_time_sliced = actual_time[1:] # 形状: (seq_len - 1)\n",
    "        actual_setting_sliced = actual_setting[1:] # 形状: (seq_len - 1)\n",
    "\n",
    "\n",
    "        return actual_time_sliced, predicted_time_abs, actual_setting_sliced, predicted_setting\n",
    "\n",
    "\n",
    "def visualize_prediction(actual_time, predicted_time, actual_setting, predicted_setting, sample_index, original_label, assigned_cluster_label):\n",
    "    \"\"\"\n",
    "    可视化单个序列的实际值与模型预测值的对比。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 序列 {sample_index} (原始标签: {original_label}, 分配到: {assigned_cluster_label}) 的步进式预测可视化 ---\")\n",
    "\n",
    "    # 获取预测序列的步数\n",
    "    num_steps_predicted = len(predicted_time)\n",
    "    if num_steps_predicted == 0:\n",
    "        print(\"没有可预测的步数来可视化。\")\n",
    "        return\n",
    "    # 创建 x 轴的步数索引 (从 1 开始，对应原始序列的索引 1 到 seq_len - 1)\n",
    "    step_indices = np.arange(1, num_steps_predicted + 1)\n",
    "\n",
    "    # 绘制时间预测对比图\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(step_indices, actual_time, label='实际时间', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(step_indices, predicted_time, label='预测时间', marker='x', linestyle='--', color='red')\n",
    "    plt.title(f'序列 {sample_index} 时间预测对比 (实际 vs 预测)')\n",
    "    plt.xlabel('预测步数 (对应原始序列索引 1 至末尾)')\n",
    "    plt.ylabel('时间')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制设置预测对比图\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # combined_setting 的值域是 0-124，直接作为 y 轴值\n",
    "    plt.plot(step_indices, actual_setting, label='实际设置', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(step_indices, predicted_setting, label='预测设置', marker='x', linestyle='--', color='red')\n",
    "    plt.title(f'序列 {sample_index} 设置预测对比 (实际 vs 预测)')\n",
    "    plt.xlabel('预测步数 (对应原始序列索引 1 至末尾)')\n",
    "    plt.ylabel('Combined Setting (0-124)')\n",
    "    # 可以设置 y 轴刻度，如果需要更精细的展示\n",
    "    # plt.yticks(np.arange(0, 125, 10)) # 示例：每隔 10 个类别显示一个刻度\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "setting_categories = [-2, -1, 0, 1, 2] # 假设这是您的原始 setting categories\n",
    "# 创建一个有序的 CategoricalDtype\n",
    "setting_dtype = pd.CategoricalDtype(categories=setting_categories, ordered=True)\n",
    "\n",
    "def restore_from_transformed_element(transformed_element):\n",
    "    \"\"\"\n",
    "    将一个转换后的数据元素 (来自 transformed_list) 还原为原始格式。\n",
    "\n",
    "    Args:\n",
    "        transformed_element: 列表，一个元素来自 transformed_list，格式为\n",
    "                             [transformed_dataframe, label]。\n",
    "                             transformed_dataframe 包含 'time', 'combined_setting' 列。\n",
    "                             'combined_setting' 列是 dtype='category'，其类别是 0-124 的整数。\n",
    "\n",
    "    Returns:\n",
    "        list: 还原后的元素，格式为 [restored_dataframe, label]。\n",
    "              restored_dataframe 包含 'time', 'top_setting', 'central_setting',\n",
    "              'bottom_setting' 列。这三列是 dtype='category'，其类别是 -2到2。\n",
    "    Raises:\n",
    "        ValueError: 如果输入格式不正确。\n",
    "    \"\"\"\n",
    "    if not isinstance(transformed_element, list) or len(transformed_element) != 2:\n",
    "        raise ValueError(\"Input must be a list of two elements: [dataframe, label]\")\n",
    "\n",
    "    transformed_df, label = transformed_element\n",
    "\n",
    "    if not isinstance(transformed_df, pd.DataFrame):\n",
    "         raise ValueError(\"First element of the input list must be a pandas DataFrame\")\n",
    "\n",
    "    if not all(col in transformed_df.columns for col in ['time', 'combined_setting']):\n",
    "         raise ValueError(\"Input DataFrame must contain 'time' and 'combined_setting' columns\")\n",
    "\n",
    "    # 确保 'combined_setting' 是 category 类型，并且其类别是整数 (0-124)\n",
    "    # 使用 .astype(int) 来获取其内部整数表示\n",
    "    try:\n",
    "        combined_values = transformed_df['combined_setting'].astype(int)\n",
    "    except ValueError as e:\n",
    "         raise ValueError(f\"Could not convert 'combined_setting' to int, check category values: {e}\")\n",
    "\n",
    "\n",
    "    # 逆转五进制编码 (分解)\n",
    "    # combined_setting_id = mapped_top * 25 + mapped_central * 5 + mapped_bottom * 1\n",
    "    # mapped values are 0-4, corresponding to -2 to 2\n",
    "\n",
    "    mapped_top = combined_values // 25         # 整数除法\n",
    "    remainder = combined_values % 25           # 取余数\n",
    "    mapped_central = remainder // 5\n",
    "    mapped_bottom = remainder % 5              # 或者 remainder // 1, 但 % 5 更清晰表示末位\n",
    "\n",
    "    # 逆转映射 (将 0-4 还原到 -2-2)\n",
    "    top_setting_numeric = mapped_top - 2\n",
    "    central_setting_numeric = mapped_central - 2\n",
    "    bottom_setting_numeric = mapped_bottom - 2\n",
    "\n",
    "    # 创建新的 DataFrame，包含原始 time 和还原后的三列设置\n",
    "    restored_df = pd.DataFrame({\n",
    "        'time': transformed_df['time'],\n",
    "        'top_setting': top_setting_numeric,\n",
    "        'central_setting': central_setting_numeric,\n",
    "        'bottom_setting': bottom_setting_numeric\n",
    "    })\n",
    "\n",
    "    # 将还原后的设置列转换为 category 类型，使用之前定义的有序类别和 dtype\n",
    "    for col in ['top_setting', 'central_setting', 'bottom_setting']:\n",
    "        # 确保转换后的数值在 [-2, 2] 范围内，否则 astype(setting_dtype) 可能产生 NaN\n",
    "        # 如果编码正确，这应该是保证的\n",
    "        try:\n",
    "            restored_df[col] = restored_df[col].astype(setting_dtype)\n",
    "        except ValueError as e:\n",
    "             print(f\"警告: 还原列 '{col}' 包含超出类别范围的值，转换为 category 时可能出现 NaN: {e}\")\n",
    "             restored_df[col] = pd.Categorical(restored_df[col], categories=setting_categories, ordered=True) # 即使有超出范围的也尝试转换\n",
    "\n",
    "    # 返回还原后的 [dataframe, label] 元素\n",
    "    return [restored_df, label]\n",
    "\n",
    "def calculate_row_condition_proportion(data_list, condition_func):\n",
    "    \"\"\"\n",
    "    计算一个列表中的所有 DataFrame 合并后，满足特定行条件的比例。\n",
    "\n",
    "    Args:\n",
    "        data_list: 列表，每个元素是 [dataframe, label]。\n",
    "        condition_func: 一个函数，接收一个 DataFrame 的行 (Pandas Series)，返回 True 或 False。\n",
    "\n",
    "    Returns:\n",
    "        float: 满足条件的行数 / 总行数。如果总行数为 0，返回 0.0。\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for df, _ in data_list:\n",
    "        if df is not None and not df.empty:\n",
    "             # 确保只选择 setting 列\n",
    "             all_rows.append(df[['top_setting', 'central_setting', 'bottom_setting']].astype(int)) # 将 category 转为 int 进行计算\n",
    "\n",
    "    if not all_rows:\n",
    "        return 0.0 # 没有数据框或数据框为空\n",
    "\n",
    "    combined_df = pd.concat(all_rows, ignore_index=True)\n",
    "    total_rows = len(combined_df)\n",
    "\n",
    "    if total_rows == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # 使用 apply along axis 1 to check condition for each row\n",
    "    # condition_func will receive a Series representing a row of setting columns\n",
    "    # pandas apply can be slow, but for clarity let's use it first.\n",
    "    # A vectorized approach is better if possible.\n",
    "\n",
    "    # Vectorized approach for the specific conditions required:\n",
    "\n",
    "    # Condition: exactly one setting is non-zero\n",
    "    if condition_func.__name__ == 'is_one_setting_nonzero':\n",
    "         # Count non-zero settings in each row (0 for non-zero, 1 for zero)\n",
    "         # Summing booleans treats True as 1, False as 0\n",
    "         num_nonzero = (combined_df != 0).sum(axis=1) # axis=1 sums across columns for each row\n",
    "         satisfied_rows = (num_nonzero == 1).sum() # Count rows where num_nonzero is exactly 1\n",
    "\n",
    "    # Condition: any setting is 1 or -1\n",
    "    elif condition_func.__name__ == 'is_any_setting_1_or_neg1':\n",
    "         # Check if any setting in the row is 1 or -1\n",
    "         is_1_or_neg1 = combined_df.isin([1, -1]) # Boolean DataFrame of same shape\n",
    "         satisfied_rows = is_1_or_neg1.any(axis=1).sum() # Check if 'any' is True in each row, then sum\n",
    "\n",
    "    else:\n",
    "         # Fallback to apply for general condition functions (less efficient)\n",
    "         print(f\"警告: 使用通用的 apply 方法计算条件 '{condition_func.__name__}' 的比例，效率较低。\")\n",
    "         satisfied_rows = combined_df.apply(condition_func, axis=1).sum()\n",
    "\n",
    "\n",
    "    return satisfied_rows / total_rows\n",
    "\n",
    "\n",
    "# Helper condition functions for clarity\n",
    "def is_one_setting_nonzero(row):\n",
    "     # row is a Pandas Series of shape (3,) representing ['top', 'central', 'bottom'] settings\n",
    "     # Convert to numpy array for boolean calculation\n",
    "     settings = row.values\n",
    "     # Count how many settings are not equal to 0\n",
    "     num_nonzero = np.sum(settings != 0)\n",
    "     return num_nonzero == 1\n",
    "\n",
    "def is_any_setting_1_or_neg1(row):\n",
    "    # row is a Pandas Series of shape (3,)\n",
    "    settings = row.values\n",
    "    # Check if any setting is equal to 1 or -1\n",
    "    return np.any((settings == 1) | (settings == -1))\n",
    "\n",
    "\n",
    "def calculate_label_proportion(data_list, target_label):\n",
    "    \"\"\"\n",
    "    计算一个列表中元素标签为特定字符串的比例。\n",
    "\n",
    "    Args:\n",
    "        data_list: 列表，每个元素是 [dataframe, label]。\n",
    "        target_label: 目标标签字符串。\n",
    "\n",
    "    Returns:\n",
    "        float: 标签为 target_label 的元素数量 / 列表总元素数量。如果列表为空，返回 0.0。\n",
    "    \"\"\"\n",
    "    total_elements = len(data_list)\n",
    "    if total_elements == 0:\n",
    "        return 0.0\n",
    "\n",
    "    target_label_count = sum(1 for df, label in data_list if label == target_label)\n",
    "\n",
    "    return target_label_count / total_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7482fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_list = filtered_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bb806f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:总共生成 31322 条模拟序列 (0 条干扰项)。\n",
      "\n",
      "--- 运行基于 RNN (预测 delta_t) 的聚类算法 (带干扰项处理) ---\n",
      "开始基于 RNN 的聚类，共有 31322 条序列，聚成 3 类 + 1 干扰类 (3)。\n",
      "初始随机分配到主簇 (长度>=3 的序列): [10638 10274 10410]\n",
      "初始未分配序列 (长度<3): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90d9e3757b045d180d0f115a46815ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EM 迭代总进度:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 1: M 步 (训练模型)，当前活跃序列数: 31322 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec67145bbf304e1589f622056a3ecc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b901cd1b0d4cb9b8410df6f5c1fdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f418ffe5ba54f8983ef2d8ce4925d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bf963f294843789e5420197bfc4953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fbec64250141c7a94d567486a0dfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 0 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0809764af940405193282d5532756c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 1: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31322 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdf2432b33646208aa2ace06741021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  干扰项检测尚未开始。\n",
      "  31322 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 20879 条改变了主簇 (66.66%)。\n",
      "  当前分组统计: [    0 11322 10930  9070     0]\n",
      "    (-1: 0, 0-2: [11322 10930  9070], 3: 0)\n",
      "\n",
      "--- 迭代 2: M 步 (训练模型)，当前活跃序列数: 31322 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8503f70c95f64e31a63c78855a28bef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0a168663f4b04ae0323f7317eca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2267ee755a0b48ddaad2ddfd8312d443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6696146ac846c6908c843cb7f37530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c692a793e0134719bc0f5fe849213407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 1 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de4dacd383043f79ac4da34fcb645b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 2: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31322 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad9620d6bf443ba9b93a2faa422b127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 20 条。\n",
      "  31302 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 3622 条改变了主簇 (11.56%)。\n",
      "  当前分组统计: [    0 10410 11246  9646    20]\n",
      "    (-1: 0, 0-2: [10410 11246  9646], 3: 20)\n",
      "\n",
      "--- 迭代 3: M 步 (训练模型)，当前活跃序列数: 31302 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6777ba24bd96418f8d5b6fbcca36d8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75384fe5a3b843be9f1d29a302b17103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7129f5bcac4dec97f2794f3d674f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bb875c3afb4ad38c14b0b59fad7131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a6b9dc00e84ee58ea66ea13e4b0f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 2 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b26cbe2fb84314b57da9898e408f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 3: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31302 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8abce1e36944159542f1c92bdfdaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 40 条。\n",
      "  31282 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 2121 条改变了主簇 (6.77%)。\n",
      "  当前分组统计: [    0 10129 11153 10000    40]\n",
      "    (-1: 0, 0-2: [10129 11153 10000], 3: 40)\n",
      "\n",
      "--- 迭代 4: M 步 (训练模型)，当前活跃序列数: 31282 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cc8757aa284157bc902a2a0ae31cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 0) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b57abd5d7c74a87b8e384d6d4a2204c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb210ba6e7464651b49485526e988515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 1) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e999bba67ef4e02b89bec6f8be7acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/349 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b4450b16524117bbaa2ba38005bfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "迭代 3 (模型 2) 训练:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb443de0b684f28b98e987052528604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 迭代 4: E 步 (重分配序列及干扰项检测) ---\n",
      "  计算 31282 条候选序列在每个模型上的平均损失...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0d307dcc984f4eb55b6242710fbda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算损失:   0%|          | 0/31282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  进行干扰项检测...\n",
      "  本轮标记 20 条序列为干扰项。总计已标记 60 条。\n",
      "  31262 条长度 >= 3 的序列被重新分配到主簇。\n",
      "  未被标记干扰项且已分配到主簇的序列中，有 1328 条改变了主簇 (4.24%)。\n",
      "收敛达成。总分组改变比例 (4.24%) 低于阈值 (5.00%)。\n",
      "\n",
      "--- 聚类完成 ---\n",
      "最终各簇包含的序列数量 (0-2 是主簇, 3 是干扰簇):\n",
      "簇 0-2: [ 9931 11258 10073], 干扰项 (3): 60\n",
      "\n",
      "--- 聚类结果可视化 ---\n",
      "\n",
      "原始标签与分配到的簇的交叉表:\n",
      "分配到的簇   簇_0    簇_1    簇_2  干扰项\n",
      "原始标签                          \n",
      "       9931  11258  10073   60\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seeds=0\n",
    "while(1):\n",
    "    seeds +=1000\n",
    "    random.seed(seeds)\n",
    "    np.random.seed(seeds)\n",
    "    torch.manual_seed(seeds)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seeds)\n",
    "        torch.backends.cudnn.deterministic = True # 确保 CUDA 确定性算法\n",
    "    \n",
    "    TOTAL_SEQUENCES = len(transformed_list) # 更新总序列数常量\n",
    "\n",
    "    print(f\"{seeds}:总共生成 {TOTAL_SEQUENCES} 条模拟序列 ({len([item for item in transformed_list if item[1] == \"rand_label\"])} 条干扰项)。\")\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 运行聚类算法\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    print(f\"\\n--- 运行基于 RNN (预测 delta_t) 的聚类算法 (带干扰项处理) ---\")\n",
    "    # 修复：将 high_loss_threshold 参数名改为 high_avg_loss_threshold\n",
    "    final_models, final_assignments, removed_interference_indices_final = run_rnn_clustering(\n",
    "        transformed_list=transformed_list,\n",
    "        num_main_models=NUM_MAIN_MODELS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_rnn_layers=NUM_RNN_LAYERS,\n",
    "        num_categories=NUM_COMBINED_SETTINGS,\n",
    "        time_scaler=TIME_LOSS_SCALER, # 注意：这里可能需要根据实际 delta_t 值的范围调整 scaler\n",
    "        setting_scaler=SETTING_LOSS_SCALER,\n",
    "        total_iterations=TOTAL_EM_ITERATIONS, # 使用更新后的迭代次数\n",
    "        convergence_threshold=CONVERGENCE_THRESHOLD,\n",
    "        epoch_schedule=EPOCH_SCHEDULE, # 使用更新后的 epoch 计划表\n",
    "        batch_size=BATCH_SIZE,\n",
    "        early_iter_batch_threshold=EARLY_ITER_BATCH_THRESHOLD, # 使用更新后的阈值\n",
    "        early_iter_batch_percent=EARLY_ITER_BATCH_PERCENT,\n",
    "        interference_cluster_label=INTERFERENCE_CLUSTER_LABEL, # 干扰项簇标签\n",
    "        interference_detection_start_iter=INTERFERENCE_DETECTION_START_ITER, # 干扰项检测起始迭代\n",
    "        high_avg_loss_threshold=HIGH_AVG_LOSS_THRESHOLD, # 高平均损失阈值\n",
    "        num_rand_sequences=NUM_RAND_SEQUENCES # 已知的干扰项数量 (用于选出最高损失的 N 个)\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # 聚类结果可视化 (包含干扰项类别)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    visualize_clustering_results(transformed_list, final_assignments, NUM_MAIN_MODELS, INTERFERENCE_CLUSTER_LABEL)\n",
    "    # 初始化四个空列表，对应簇 0, 1, 2 和 3 (干扰项)\n",
    "    # 这些列表将存储还原后的 [dataframe, label] 元素\n",
    "    cluster_1 = [] # 对应簇 0\n",
    "    cluster_2 = [] # 对应簇 1\n",
    "    cluster_3 = [] # 对应簇 2\n",
    "    trival_cluster = [] # 对应簇 3 (干扰项)\n",
    "\n",
    "    # 创建一个字典，将簇索引映射到对应的列表\n",
    "    cluster_map = {\n",
    "        0: cluster_1,\n",
    "        1: cluster_2,\n",
    "        2: cluster_3,\n",
    "        INTERFERENCE_CLUSTER_LABEL: trival_cluster # 使用常量\n",
    "    }\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b209bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=final_models[0]\n",
    "model2=final_models[1]\n",
    "model3=final_models[2]\n",
    "\n",
    "torch.save(model1,\"model1_ticket.pth\")\n",
    "torch.save(model2,\"model2_ticket.pth\")\n",
    "torch.save(model3,\"model3_ticket.pth\")\n",
    "np.save(\"Final_assignments_ticket.npy\", final_assignments)\n",
    "with open('LoadedList_ticket.pkl', 'wb') as file:\n",
    "    pickle.dump(transformed_list, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
