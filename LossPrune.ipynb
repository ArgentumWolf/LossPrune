{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d336cc9",
   "metadata": {},
   "source": [
    "# 调包与参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "081df27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacleanv2 import *\n",
    "from SetRNN import *\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from collections import Counter # 用于统计计数的工具\n",
    "import time # 用于计时\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils # 用于处理变长序列，如填充和打包\n",
    "from torch.utils.data import Dataset, DataLoader # PyTorch 数据加载工具\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # 进度条库，使用 tqdm.tqdm\n",
    "import random\n",
    "import pyreadstat\n",
    "import copy # 用于复制模型参数或列表\n",
    "import matplotlib.pyplot as plt # 用于绘图\n",
    "import seaborn as sns # 用于更美观的统计图，特别是热力图\n",
    "import pickle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 0.3\n",
    "\n",
    "# 超参数和常量定义\n",
    "NUM_MAIN_MODELS = 3 # 主要的聚类模型数量\n",
    "NUM_COMBINED_SETTINGS = 23 # combined_setting 的总类别数 (0-124)\n",
    "EMBEDDING_DIM = 8 # combined_setting 的嵌入向量维度，可调整\n",
    "HIDDEN_SIZE = 64   # RNN 隐藏层大小，可调整\n",
    "NUM_RNN_LAYERS = 2 # RNN 层数\n",
    "# 注意: TIME_LOSS_SCALER 可能需要根据实际 delta_t 的规模重新调整\n",
    "TIME_LOSS_SCALER = 1 # time delta_t MSE 损失的缩放因子，需要根据实际损失值大小调整\n",
    "TOTAL_EM_ITERATIONS = 10 # EM 迭代总次数 (根据要求修改为 10)\n",
    "CONVERGENCE_THRESHOLD = 0.05 # 收敛阈值，分配改变的序列比例低于此值时停止 (5%)\n",
    "\n",
    "# 干扰项处理参数\n",
    "NUM_RAND_SEQUENCES = 250 # 干扰项的已知数量\n",
    "INTERFERENCE_CLUSTER_LABEL = 3 # 将干扰项分配到的簇的索引 (0, 1, 2 是主簇，3 是干扰簇)\n",
    "INTERFERENCE_DETECTION_START_ITER = 2 # 从第 5 轮迭代 (索引 4) 的 E 步开始检测干扰项\n",
    "# 检测干扰项的高损失阈值：需要根据训练中观察到的损失值范围来调整\n",
    "# 如果一个序列在所有模型上的平均损失超过这个阈值，则可能被认为是干扰项。\n",
    "# ！！！重要参数，需要根据实际运行观察的损失值调整！！！\n",
    "# 在模拟数据上运行一次，观察损失值的分布，尤其是 rand_label 序列的损失。\n",
    "HIGH_AVG_LOSS_THRESHOLD = 0.5 ## <--- !!! 初始值，请务必根据实际情况调整 !!!\n",
    "\n",
    "# M 步训练参数 (每个 EM 迭代中的训练 epochs)\n",
    "# epochs 计划表：根据迭代次数使用不同数量的 epochs\n",
    "EPOCH_SCHEDULE = [1] * 5 + [2]* 5 # 示例：前 3 轮迭代训练 2 epoch，接下来 7 轮训练 5 epoch (适应总迭代 10)\n",
    "BATCH_SIZE = 32 # M 步训练时的批次大小\n",
    "# 在早期迭代中是否只使用部分批次来加速训练\n",
    "EARLY_ITER_BATCH_THRESHOLD = 3 # 在前 3 轮迭代中使用部分批次 (适应总迭代 10)\n",
    "EARLY_ITER_BATCH_PERCENT = 0.3 # 在启用部分批次训练时使用的批次比例 (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f092527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d84ce4a",
   "metadata": {},
   "source": [
    "# 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "560d654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossCalculate(loaded_list,final_assignment_list,Model,models):\n",
    "    '''\n",
    "    参数\n",
    "        Loaded_list:载入的数据list,其中元素为数据框与一个字符串,数据框有time和combined_setting两个行,长度不小于3。\n",
    "        final_assignment_list:在rnn cluster中每个序列分配的模型的索引,长度与loaded_list相同\n",
    "        Model:一个RNN评估模型,在所有数据上训练得到\n",
    "        models:一个列表,作为RNN分类模型,元素为rnn cluster过程中产生的RNN模型\n",
    "    返回\n",
    "        total_loss_list,setting_loss_list,time_loss_list:双层list,储存每一个序列的每一步的损失值,分别为总和、setting列和time列的损失值。第i个元素的第j个元素即为第i个“output序列”\n",
    "        的第j个delta_T和第j个setting的损失。\n",
    "    使用第t步的设置和第t步到第t+1步的时间差作为输入,预测第t+1步的设置和第t+1步到t+2步的时间差\n",
    "    '''\n",
    "    #计算每个序列的损失\n",
    "    setting_loss_list=[None]*len(loaded_list)\n",
    "    time_loss_list=[None]*len(loaded_list)\n",
    "    for i in range(len(loaded_list)):\n",
    "        seq_time=torch.FloatTensor(loaded_list[i][0][\"time\"].values)\n",
    "        seq_setting=torch.LongTensor(loaded_list[i][0][\"combined_setting\"].values)\n",
    "        time_criterion = nn.MSELoss(reduction= \"sum\")\n",
    "        setting_criterion = nn.CrossEntropyLoss(reduction= \"sum\")\n",
    "        if final_assignment_list[i] >= len(models):\n",
    "            setting_loss_list[i] = [0]\n",
    "            time_loss_list[i] = [0]\n",
    "            continue\n",
    "        model = Model\n",
    "\n",
    "        #deltaT_inputs是时间差的输入，setting_inputs是设置的输入\n",
    "        #使用第t步的设置和第t步到第t+1步的时间差作为输入，预测第t+1步的设置和第t+1步到t+2步的时间差\n",
    "        deltaT_inputs=(seq_time[1:-1] - seq_time[:-2]).unsqueeze(0).to(device)\n",
    "        setting_inputs=seq_setting[0:-2].unsqueeze(0).to(device)\n",
    "\n",
    "        deltaT_targets=(seq_time[2:] - seq_time[1:-1]).unsqueeze(0).to(device)\n",
    "        setting_targets=seq_setting[1:-1].unsqueeze(0).to(device)\n",
    "\n",
    "        input_len = seq_time.shape[0] - 2#输出输出的长度\n",
    "        length = torch.tensor([input_len])\n",
    "\n",
    "        #模型预测\n",
    "        predict_deltaT, predict_setting,_ = model(deltaT_inputs, setting_inputs, length)\n",
    "        \n",
    "        #计算损失\n",
    "        seq_time_loss_tensor=[time_criterion(predict_deltaT.squeeze(0)[i], deltaT_targets.squeeze(0)[i]) for i in range(predict_deltaT.squeeze(0).shape[0])]\n",
    "        seq_setting_loss_tensor=[setting_criterion(predict_setting.squeeze(0)[i].unsqueeze(0), setting_targets.squeeze(0)[i].unsqueeze(0)) for i in range(predict_setting.squeeze(0).shape[0])]\n",
    "        \n",
    "        seq_setting_loss_list=[_.item() for _ in seq_time_loss_tensor]\n",
    "        seq_time_loss_list=[_.item() for _ in seq_setting_loss_tensor]\n",
    "        setting_loss_list[i]=seq_setting_loss_list\n",
    "        time_loss_list[i]=seq_time_loss_list\n",
    "\n",
    "    #total_loss_list代表每个列表每一步的总损失\n",
    "    total_loss_list = [[setting_loss_list[i][j]+ time_loss_list[i][j] for j in range(len(setting_loss_list[i]))]for i in range(len(setting_loss_list)) ]\n",
    "    return total_loss_list,setting_loss_list,time_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "366ec9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ThresholdCalculate(total_loss_list,setting_loss_list,time_loss_list,threshold):\n",
    "    '''\n",
    "    参数:\n",
    "        total_loss_list,setting_loss_list,time_loss_list:双层list,储存每一个序列的每一步的损失值,分别为总和、setting列和time列的损失值。第i个元素的第j个元素即为第i个“output序列”\n",
    "        的第j个delta_T和第j个setting的损失。\n",
    "        threshold:一个百分比值,代表要被删掉的序列的比例\n",
    "    返回:\n",
    "        setting_threshold,time_threshold,total_threshold:三个阈值,分别为setting列,time列和总损失的阈值,低于该阈值的序列将被删除;\n",
    "        total_step_length:所有序列总的步骤数\n",
    "    '''\n",
    "    setting_loss_distribution=[item for list_item in setting_loss_list for item in list_item]\n",
    "    time_loss_distribution=[item for list_item in time_loss_list for item in list_item]\n",
    "    total_loss_distribution=[item for list_item in total_loss_list for item in list_item]\n",
    "\n",
    "    setting_threshold = np.percentile(setting_loss_distribution, threshold)\n",
    "    time_threshold = np.percentile(time_loss_distribution, threshold)\n",
    "    total_threshold = np.percentile(total_loss_distribution, threshold)\n",
    "\n",
    "    total_step_length=len(total_loss_distribution)\n",
    "    \n",
    "    return setting_threshold,time_threshold,total_threshold,total_step_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0501af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prune(loaded_list,outliers,i,final_assignment_list,models):\n",
    "    '''\n",
    "    功能：将loaded_list中第i个序列的outliers中标记的异常点删除,并返回删除后的数据张量\n",
    "    参数\n",
    "        Loaded_list:载入的数据list,其中元素为数据框与一个字符串,数据框有time和combined_setting两个行,长度不小于3。\n",
    "        outliers:一个列表,元素为元组(i,j),代表第i个序列的第j个步骤被认为是异常值,需要被删除\n",
    "        i:当前是第i个序列,用于获取索引\n",
    "        final_assignment_list:在rnn cluster中每个序列分配的模型的索引,长度与loaded_list相同\n",
    "        models:一个列表,作为RNN分类模型,元素为rnn cluster过程中产生\n",
    "    返回\n",
    "        如果返回\n",
    "            None,则continue\n",
    "        否则返回\n",
    "            pruned_deltaT_inputs, pruned_setting_inputs, pruned_deltaT_targets, pruned_setting_targets, pruned_length:分别为被删除后的时间间隔和setting的输入和输出张量,以及数据长度张量\n",
    "    '''\n",
    "    seq_time=torch.FloatTensor(loaded_list[i][0][\"time\"].values)\n",
    "    seq_setting=torch.LongTensor(loaded_list[i][0][\"combined_setting\"].values)\n",
    "    \n",
    "    if final_assignment_list[i] >= len(models):\n",
    "        return None\n",
    "\n",
    "    #deltaT_inputs是时间差的输入，setting_inputs是设置的输入\n",
    "    #使用第t步的设置和第t步到第t+1步的时间差作为输入，预测第t+1步的设置和第t+1步到t+2步的时间差\n",
    "    deltaT_inputs=(seq_time[1:-1] - seq_time[:-2]).unsqueeze(0).to(device)\n",
    "    setting_inputs=seq_setting[0:-2].unsqueeze(0).to(device)\n",
    "\n",
    "    deltaT_targets=(seq_time[2:] - seq_time[1:-1]).unsqueeze(0).to(device)\n",
    "    setting_targets=seq_setting[1:-1].unsqueeze(0).to(device)\n",
    "\n",
    "    input_len = seq_time.shape[0] - 2#输出输出的长度\n",
    "    length = torch.tensor([input_len])\n",
    "    \n",
    "    #复制原始输入和目标张量，以便在删除异常点后进行修剪,将张量转换为列表（保留二维结构）,存入“pruned_...类型_输入/输出_list”中\n",
    "    pruned_deltaT_inputs_list, pruned_setting_inputs_list, pruned_deltaT_targets_list, pruned_setting_targets_list= deltaT_inputs.clone().tolist(), setting_inputs.clone().tolist(), deltaT_targets.clone().tolist(), setting_targets.clone().tolist()\n",
    "    indices_to_remove = [y for _, y in outliers if _ ==i]# 从outlier中提取所有序列标号为i的异常点（即第一个元素为i的数组),忽略x，只取y\n",
    "    indices_to_remove = sorted(list(set(indices_to_remove)),reverse=True)  # 去重,降序排序(先删后面的，避免改变索引位置),indices_to_remove是储存第i个序列中需要删除的索引列表,注意sorted和.sort的区别\n",
    "    #***测试用待删print(i,indices_to_remove)\n",
    "\n",
    "    # 如果没有可删除的，则直接返回None\n",
    "    if not indices_to_remove:\n",
    "        return None\n",
    "    \n",
    "    # 如果所有步骤都是异常点，则跳过\n",
    "    # ***是否要记录所有步骤都异常的序列的总数**？\n",
    "    if len(pruned_deltaT_inputs_list[0]) == len(indices_to_remove):\n",
    "        #***print(\"序列\",i,\"的所有步骤均为异常点，跳过\")#提示均为异常点\n",
    "        return -1\n",
    "    for index in indices_to_remove:\n",
    "        # 检查索引index是否在有效范围内\n",
    "        if 0 <= index < len(pruned_deltaT_inputs_list[0]):# 删除被标记的步骤 <bug:只删去了t_input的异常点,忘记了其他的>\n",
    "            del pruned_deltaT_inputs_list[0][index]\n",
    "            del pruned_setting_inputs_list[0][index]\n",
    "            del pruned_deltaT_targets_list[0][index]\n",
    "            del pruned_setting_targets_list[0][index]\n",
    "        else:\n",
    "            # 可选：处理索引越界情况（例如打印警告或忽略）\n",
    "            print(f\"警告: 索引 {index} 超出范围，忽略删除\")\n",
    "            # 或者直接忽略\n",
    "\n",
    "    pruned_deltaT_inputs, pruned_setting_inputs, pruned_deltaT_targets, pruned_setting_targets = torch.tensor(pruned_deltaT_inputs_list).to(device),torch.tensor(pruned_setting_inputs_list).to(device), torch.tensor(pruned_deltaT_targets_list).to(device), torch.tensor(pruned_setting_targets_list).to(device)# 现在，pruned_()_() 就是删除异常点后的数据链,<bug:忘记使用to(device)>\n",
    "    pruned_length = torch.tensor([pruned_deltaT_inputs.shape[1]])#pruned_length为删除后的长度，从数据中取，并转化为张量\n",
    "    return pruned_deltaT_inputs, pruned_setting_inputs, pruned_deltaT_targets, pruned_setting_targets,pruned_length\n",
    "\n",
    "    #***检验用待删print(pruned_deltaT_inputs_list.shape,pruned_length, pruned_setting_inputs.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7339806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reclassify(loaded_list,models,final_assignment_list,outliers):\n",
    "    '''\n",
    "    参数:\n",
    "        loaded_list:载入的数据list,其中元素为数据框与一个字符串,数据框有time和combined_setting两个行,长度不小于3。\n",
    "        models:一个列表,作为RNN分类模型,元素为rnn cluster过程中产生的RNN模型\n",
    "        final_assignment_list:在rnn cluster中每个序列分配的模型的索引,长度与loaded_list相同\n",
    "        outliers:一个列表,元素为元组(i,j),代表第i个序列的第j个步骤被认为是异常值,需要被删除\n",
    "    返回:\n",
    "        changed_seq:一个列表,储存被重新分类的序列的索引\n",
    "    '''\n",
    "    time_criterion = nn.MSELoss(reduction= \"sum\")\n",
    "    setting_criterion = nn.CrossEntropyLoss(reduction= \"sum\")\n",
    "    changed_seq=[]\n",
    "    Null_seq=[]\n",
    "    for i in range(len(loaded_list)):#第i个序列\n",
    "        pruned_data = Prune(loaded_list, outliers, i, final_assignment_list, models)\n",
    "        #使用Prune函数删除异常点,返回删除后的数据序列\n",
    "        if pruned_data is None:\n",
    "            continue\n",
    "        if pruned_data == -1:\n",
    "            Null_seq.append(i)\n",
    "            continue\n",
    "        pruned_deltaT_inputs, pruned_setting_inputs, pruned_deltaT_targets, pruned_setting_targets, pruned_length = pruned_data\n",
    "        \n",
    "        #使用所有模型分别计算损失\n",
    "        model_loss = [0] * len(models) # 初始化每个模型的损失列表\n",
    "        for j in range(len(models)):\n",
    "            model = models[j]\n",
    "            #模型预测\n",
    "            pruned_predict_deltaT, pruned_predict_setting,_ = model(pruned_deltaT_inputs, pruned_setting_inputs, pruned_length)\n",
    "\n",
    "            #计算损失,seq代表按每一步计损失并编入列表\n",
    "            pruned_seq_time_loss_list=[time_criterion(pruned_predict_deltaT.squeeze(0)[i], pruned_deltaT_targets.squeeze(0)[i]).item() for i in range(pruned_predict_deltaT.squeeze(0).shape[0])]\n",
    "            pruned_seq_setting_loss_list=[setting_criterion(pruned_predict_setting.squeeze(0)[i].unsqueeze(0), pruned_setting_targets.squeeze(0)[i].unsqueeze(0)).item() for i in range(pruned_predict_setting.squeeze(0).shape[0])]\n",
    "\n",
    "            model_loss[j] = sum(pruned_seq_setting_loss_list)+ sum(pruned_seq_time_loss_list) # 计算剪后序列i在模型j上的总损失\n",
    "            #***测试用待删print(model_loss[j])\n",
    "\n",
    "        min_modelloss = min(model_loss)\n",
    "        min_modelindex = model_loss.index(min_modelloss)#找出剪后的最佳模型\n",
    "        if min_modelindex != final_assignment_list[i] and final_assignment_list[i] < len(models):#若与原分配不同，则打印并记录\n",
    "            #***用于提示：print(\"序列\",i,\"的最佳模型由\",final_assignment_list[i],\"变为\",min_modelindex)\n",
    "            changed_seq.append(i)\n",
    "        #else:\n",
    "        #    ***测试用待删print(\"模型损失:\",model_loss,\"序号不变\",final_assignment_list[i])#<bug:在print()立马加入print(model_loss)会输出None>\n",
    "    return changed_seq,Null_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe615ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossPrune(loaded_list,final_assignment_list,models,threshold,total_loss_list,setting_loss_list,time_loss_list):\n",
    "    '''\n",
    "    参数\n",
    "        Loaded_list:载入的list,其中元素为数据框与一个字符串,数据框有time和combined_setting两个行,长度不小于3。\n",
    "        final_assignment_list:在rnn cluster中每个序列分配的模型的索引,长度与loaded_list相同\n",
    "        models:一个列表,作为RNN分类模型,元素为rnn cluster过程中产生的RNN模型\n",
    "        threshold:一个百分比值,代表要被删掉的序列的比例\n",
    "        total_loss_list,setting_loss_list,time_loss_list:双层list,储存每一个序列的每一步的损失值,分别为总和、setting列和time列的损失值。第i个元素的第j个元素即为第i个“output序列”\n",
    "    返回\n",
    "        分类改变的序列占总序列的比例、总序列的个数、被删改的序列个数、分类改变的序列的个数\n",
    "    '''\n",
    "    setting_threshold,time_threshold,total_threshold,total_step_length=ThresholdCalculate(total_loss_list,setting_loss_list,time_loss_list,threshold)#计算每种损失的阈值\n",
    "    outliers = [(i, j) for i, chain in enumerate(total_loss_list) for j, loss in enumerate(chain) if loss < total_threshold]#找出所有异常值,储存为(i,j)的元组,代表第i个序列的第j个步骤被认为是异常值,需要被删除\n",
    "    \n",
    "    print(\"共从\",total_step_length,\"个步骤中检测到\",len(outliers),\"个异常值\")\n",
    "    changed_seq,Null_seq=Reclassify(loaded_list,models,final_assignment_list,outliers)#找出重新分类之后被改变的序列\n",
    "\n",
    "    print(\"压缩比例:\",threshold,\";类别改变比例\",len(changed_seq)/len(loaded_list))\n",
    "    print(\"{:<10}\".format(\"总序列数\"),len(loaded_list))\n",
    "    print(\"{:<15}\".format(\"被重新分类数\"),len(set([i[0] for i in outliers])))\n",
    "    print(\"{:<10}\".format(\"被改变类别数\"),len(changed_seq))\n",
    "\n",
    "    return len(changed_seq)/len(loaded_list),len(loaded_list),len(set([i[0] for i in outliers])),len(changed_seq),len(Null_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab43ec",
   "metadata": {},
   "source": [
    "# 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50a2c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 98, 99] # 压缩比例列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f3bf5",
   "metadata": {},
   "source": [
    "## Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc84af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63dca9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_COMBINED_SETTINGS = 23\n",
    "with open('LoadedList_Traffic.pkl', 'rb') as f:  # 'rb' 表示二进制读取模式\n",
    "    loaded_list = pickle.load(f)  # 从文件读取并反序列化#载入数据\n",
    "final_assignment_list= np.load(\"Final_assignments_Traffic.npy\")\n",
    "\n",
    "models = [SettingPredictorRNN(embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_rnn_layers=NUM_RNN_LAYERS, num_categories=NUM_COMBINED_SETTINGS).to(device) for _ in range(NUM_MAIN_MODELS)]\n",
    "models[0] = torch.load(\"model1_traffic.pth\",weights_only=False)\n",
    "models[1] = torch.load(\"model2_traffic.pth\",weights_only=False)   \n",
    "models[2] = torch.load(\"model3_traffic.pth\",weights_only=False)\n",
    "Model = torch.load(\"TotalModel_traffic.pth\",weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共从 791979 个步骤中检测到 79198 个异常值\n",
      "压缩比例: 10 ;类别改变比例 0.02883502035632914\n",
      "总序列数       26773\n",
      "被重新分类数          19730\n",
      "被改变类别数     772\n",
      "共从 791979 个步骤中检测到 158396 个异常值\n",
      "压缩比例: 20 ;类别改变比例 0.05539162589175662\n",
      "总序列数       26773\n",
      "被重新分类数          23304\n",
      "被改变类别数     1483\n",
      "共从 791979 个步骤中检测到 237594 个异常值\n",
      "压缩比例: 30 ;类别改变比例 0.08359167818324431\n",
      "总序列数       26773\n",
      "被重新分类数          24787\n",
      "被改变类别数     2238\n",
      "共从 791979 个步骤中检测到 316792 个异常值\n",
      "压缩比例: 40 ;类别改变比例 0.11209053897583386\n",
      "总序列数       26773\n",
      "被重新分类数          25462\n",
      "被改变类别数     3001\n",
      "共从 791979 个步骤中检测到 395989 个异常值\n",
      "压缩比例: 50 ;类别改变比例 0.14096291039480074\n",
      "总序列数       26773\n",
      "被重新分类数          25847\n",
      "被改变类别数     3774\n",
      "共从 791979 个步骤中检测到 475187 个异常值\n",
      "压缩比例: 60 ;类别改变比例 0.17233780301049564\n",
      "总序列数       26773\n",
      "被重新分类数          26113\n",
      "被改变类别数     4614\n",
      "共从 791979 个步骤中检测到 554385 个异常值\n",
      "压缩比例: 70 ;类别改变比例 0.21547828035707617\n",
      "总序列数       26773\n",
      "被重新分类数          26305\n",
      "被改变类别数     5769\n",
      "共从 791979 个步骤中检测到 633583 个异常值\n",
      "压缩比例: 80 ;类别改变比例 0.2893586822545101\n",
      "总序列数       26773\n",
      "被重新分类数          26468\n",
      "被改变类别数     7747\n",
      "共从 791979 个步骤中检测到 712781 个异常值\n",
      "压缩比例: 90 ;类别改变比例 0.4417883688790946\n",
      "总序列数       26773\n",
      "被重新分类数          26660\n",
      "被改变类别数     11828\n",
      "共从 791979 个步骤中检测到 752380 个异常值\n",
      "压缩比例: 95 ;类别改变比例 0.43984611362193254\n",
      "总序列数       26773\n",
      "被重新分类数          26726\n",
      "被改变类别数     11776\n",
      "共从 791979 个步骤中检测到 776139 个异常值\n",
      "压缩比例: 98 ;类别改变比例 0.23516229036716094\n",
      "总序列数       26773\n",
      "被重新分类数          26755\n",
      "被改变类别数     6296\n",
      "共从 791979 个步骤中检测到 784059 个异常值\n",
      "压缩比例: 99 ;类别改变比例 0.11276285810331305\n",
      "总序列数       26773\n",
      "被重新分类数          26767\n",
      "被改变类别数     3019\n",
      "    changed_ratios  total_seqnum  reclassified_seqnum  changed_seqnum  \\\n",
      "0         0.028835         26773                19730             772   \n",
      "1         0.055392         26773                23304            1483   \n",
      "2         0.083592         26773                24787            2238   \n",
      "3         0.112091         26773                25462            3001   \n",
      "4         0.140963         26773                25847            3774   \n",
      "5         0.172338         26773                26113            4614   \n",
      "6         0.215478         26773                26305            5769   \n",
      "7         0.289359         26773                26468            7747   \n",
      "8         0.441788         26773                26660           11828   \n",
      "9         0.439846         26773                26726           11776   \n",
      "10        0.235162         26773                26755            6296   \n",
      "11        0.112763         26773                26767            3019   \n",
      "\n",
      "    Null_seqnum  \n",
      "0            36  \n",
      "1            84  \n",
      "2           141  \n",
      "3           222  \n",
      "4           383  \n",
      "5           648  \n",
      "6          1136  \n",
      "7          2214  \n",
      "8          5154  \n",
      "9          9964  \n",
      "10        17404  \n",
      "11        21523  \n"
     ]
    }
   ],
   "source": [
    "total_loss_list,setting_loss_list,time_loss_list=LossCalculate(loaded_list,final_assignment_list,Model,models)#计算损失值\n",
    "changed_ratios=[0]*len(thresholds)\n",
    "total_seqnum=[0]*len(thresholds)\n",
    "reclassified_seqnum=[0]*len(thresholds)\n",
    "changed_seqnum=[0]*len(thresholds)\n",
    "Null_seqnum =[0]*len(thresholds)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    changed_ratios[i],total_seqnum[i],reclassified_seqnum[i],changed_seqnum[i],Null_seqnum[i]=LossPrune(loaded_list,final_assignment_list,models,threshold, total_loss_list,setting_loss_list,time_loss_list)#删除损失值最低的\n",
    "df_plot={\"changed_ratios\":changed_ratios,\"total_seqnum\":total_seqnum,\"reclassified_seqnum\":reclassified_seqnum,\"changed_seqnum\":changed_seqnum,\"Null_seqnum\":Null_seqnum}\n",
    "Traffic_df_plot = pd.DataFrame(data=df_plot)\n",
    "print(Traffic_df_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f4c01",
   "metadata": {},
   "source": [
    "## Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af01390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COMBINED_SETTINGS = 125\n",
    "with open('LoadedList_Climate.pkl', 'rb') as f:  # 'rb' 表示二进制读取模式\n",
    "    loaded_list = pickle.load(f)  # 从文件读取并反序列化#载入数据\n",
    "final_assignment_list= np.load(\"Final_assignments_Climate.npy\")\n",
    "\n",
    "models = [SettingPredictorRNN(embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_rnn_layers=NUM_RNN_LAYERS, num_categories=NUM_COMBINED_SETTINGS).to(device) for _ in range(NUM_MAIN_MODELS)]\n",
    "models[0] = torch.load(\"model1.pth\",weights_only=False)\n",
    "models[1] = torch.load(\"model2.pth\",weights_only=False)   \n",
    "models[2] = torch.load(\"model3.pth\",weights_only=False)\n",
    "Model = torch.load(\"TotalModel.pth\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfeecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共从 411695 个步骤中检测到 41170 个异常值\n",
      "压缩比例: 10 ;类别改变比例 0.047818313234678736\n",
      "总序列数       26287\n",
      "被重新分类数          14596\n",
      "被改变类别数     1257\n",
      "共从 411695 个步骤中检测到 82339 个异常值\n",
      "压缩比例: 20 ;类别改变比例 0.07383877962490965\n",
      "总序列数       26287\n",
      "被重新分类数          18670\n",
      "被改变类别数     1941\n",
      "共从 411695 个步骤中检测到 123509 个异常值\n",
      "压缩比例: 30 ;类别改变比例 0.09506600220641381\n",
      "总序列数       26287\n",
      "被重新分类数          20511\n",
      "被改变类别数     2499\n",
      "共从 411695 个步骤中检测到 164678 个异常值\n",
      "压缩比例: 40 ;类别改变比例 0.11621714155285882\n",
      "总序列数       26287\n",
      "被重新分类数          21770\n",
      "被改变类别数     3055\n",
      "共从 411695 个步骤中检测到 205847 个异常值\n",
      "压缩比例: 50 ;类别改变比例 0.14223760794308973\n",
      "总序列数       26287\n",
      "被重新分类数          22731\n",
      "被改变类别数     3739\n",
      "共从 411695 个步骤中检测到 247017 个异常值\n",
      "压缩比例: 60 ;类别改变比例 0.1708829459428615\n",
      "总序列数       26287\n",
      "被重新分类数          23479\n",
      "被改变类别数     4492\n",
      "共从 411695 个步骤中检测到 288186 个异常值\n",
      "压缩比例: 70 ;类别改变比例 0.21554380492258532\n",
      "总序列数       26287\n",
      "被重新分类数          24185\n",
      "被改变类别数     5666\n",
      "共从 411695 个步骤中检测到 329356 个异常值\n",
      "压缩比例: 80 ;类别改变比例 0.27473656179860767\n",
      "总序列数       26287\n",
      "被重新分类数          24863\n",
      "被改变类别数     7222\n",
      "共从 411695 个步骤中检测到 370525 个异常值\n",
      "压缩比例: 90 ;类别改变比例 0.32601666222847797\n",
      "总序列数       26287\n",
      "被重新分类数          25567\n",
      "被改变类别数     8570\n",
      "共从 411695 个步骤中检测到 391110 个异常值\n",
      "压缩比例: 95 ;类别改变比例 0.2824590101571119\n",
      "总序列数       26287\n",
      "被重新分类数          25900\n",
      "被改变类别数     7425\n",
      "共从 411695 个步骤中检测到 403461 个异常值\n",
      "压缩比例: 98 ;类别改变比例 0.15361205158443336\n",
      "总序列数       26287\n",
      "被重新分类数          26117\n",
      "被改变类别数     4038\n",
      "共从 411695 个步骤中检测到 407578 个异常值\n",
      "压缩比例: 99 ;类别改变比例 0.07539848594362232\n",
      "总序列数       26287\n",
      "被重新分类数          26205\n",
      "被改变类别数     1982\n",
      "    changed_ratios  total_seqnum  reclassified_seqnum  changed_seqnum  \\\n",
      "0         0.047818         26287                14596            1257   \n",
      "1         0.073839         26287                18670            1941   \n",
      "2         0.095066         26287                20511            2499   \n",
      "3         0.116217         26287                21770            3055   \n",
      "4         0.142238         26287                22731            3739   \n",
      "5         0.170883         26287                23479            4492   \n",
      "6         0.215544         26287                24185            5666   \n",
      "7         0.274737         26287                24863            7222   \n",
      "8         0.326017         26287                25567            8570   \n",
      "9         0.282459         26287                25900            7425   \n",
      "10        0.153612         26287                26117            4038   \n",
      "11        0.075398         26287                26205            1982   \n",
      "\n",
      "    Null_seqnum  \n",
      "0           505  \n",
      "1           706  \n",
      "2           868  \n",
      "3          1086  \n",
      "4          1376  \n",
      "5          1735  \n",
      "6          2360  \n",
      "7          3635  \n",
      "8          7918  \n",
      "9         13523  \n",
      "10        19686  \n",
      "11        22630  \n"
     ]
    }
   ],
   "source": [
    "total_loss_list,setting_loss_list,time_loss_list=LossCalculate(loaded_list,final_assignment_list,Model,models)#计算损失值\n",
    "changed_ratios=[0]*len(thresholds)\n",
    "total_seqnum=[0]*len(thresholds)\n",
    "reclassified_seqnum=[0]*len(thresholds)\n",
    "changed_seqnum=[0]*len(thresholds)\n",
    "Null_seqnum =[0]*len(thresholds)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    changed_ratios[i],total_seqnum[i],reclassified_seqnum[i],changed_seqnum[i],Null_seqnum[i]=LossPrune(loaded_list,final_assignment_list,models,threshold, total_loss\n",
    "                                                                                                        _list,setting_loss_list,time_loss_list)#删除损失值最低的\n",
    "df_plot={\"changed_ratios\":changed_ratios,\"total_seqnum\":total_seqnum,\"reclassified_seqnum\":reclassified_seqnum,\"changed_seqnum\":changed_seqnum,\"Null_seqnum\":Null_seqnum}\n",
    "Climate_df_plot = pd.DataFrame(data=df_plot)\n",
    "print(Climate_df_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d492b79",
   "metadata": {},
   "source": [
    "## Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b75006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COMBINED_SETTINGS = 13\n",
    "with open('LoadedList_Tickets.pkl', 'rb') as f:  # 'rb' 表示二进制读取模式\n",
    "    loaded_list = pickle.load(f)  # 从文件读取并反序列化#载入数据\n",
    "final_assignment_list= np.load(\"Final_assignments_Tickets.npy\")\n",
    "\n",
    "models = [SettingPredictorRNN(embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, num_rnn_layers=NUM_RNN_LAYERS, num_categories=NUM_COMBINED_SETTINGS).to(device) for _ in range(NUM_MAIN_MODELS)]\n",
    "models[0] = torch.load(\"model1_tickets.pth\",weights_only=False)\n",
    "models[1] = torch.load(\"model2_tickets.pth\",weights_only=False)   \n",
    "models[2] = torch.load(\"model3_tickets.pth\",weights_only=False)\n",
    "Model = torch.load(\"TotalModel_tickets.pth\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8df237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共从 216756 个步骤中检测到 21676 个异常值\n",
      "压缩比例: 10 ;类别改变比例 0.028191047825809334\n",
      "总序列数       31322\n",
      "被重新分类数          9274\n",
      "被改变类别数     883\n",
      "共从 216756 个步骤中检测到 43351 个异常值\n",
      "压缩比例: 20 ;类别改变比例 0.040801992209948276\n",
      "总序列数       31322\n",
      "被重新分类数          12021\n",
      "被改变类别数     1278\n",
      "共从 216756 个步骤中检测到 65027 个异常值\n",
      "压缩比例: 30 ;类别改变比例 0.05644594853457634\n",
      "总序列数       31322\n",
      "被重新分类数          14665\n",
      "被改变类别数     1768\n",
      "共从 216756 个步骤中检测到 86702 个异常值\n",
      "压缩比例: 40 ;类别改变比例 0.07422897643828619\n",
      "总序列数       31322\n",
      "被重新分类数          17602\n",
      "被改变类别数     2325\n",
      "共从 216756 个步骤中检测到 108378 个异常值\n",
      "压缩比例: 50 ;类别改变比例 0.0890428452844646\n",
      "总序列数       31322\n",
      "被重新分类数          20356\n",
      "被改变类别数     2789\n",
      "共从 216756 个步骤中检测到 130053 个异常值\n",
      "压缩比例: 60 ;类别改变比例 0.10165378966860354\n",
      "总序列数       31322\n",
      "被重新分类数          23197\n",
      "被改变类别数     3184\n",
      "共从 216756 个步骤中检测到 151728 个异常值\n",
      "压缩比例: 70 ;类别改变比例 0.12326799054977332\n",
      "总序列数       31322\n",
      "被重新分类数          26029\n",
      "被改变类别数     3861\n",
      "共从 216756 个步骤中检测到 173404 个异常值\n",
      "压缩比例: 80 ;类别改变比例 0.14542494093608327\n",
      "总序列数       31322\n",
      "被重新分类数          28736\n",
      "被改变类别数     4555\n",
      "共从 216756 个步骤中检测到 195080 个异常值\n",
      "压缩比例: 90 ;类别改变比例 0.12253368239576017\n",
      "总序列数       31322\n",
      "被重新分类数          30530\n",
      "被改变类别数     3838\n",
      "共从 216756 个步骤中检测到 205918 个异常值\n",
      "压缩比例: 95 ;类别改变比例 0.06522571994125535\n",
      "总序列数       31322\n",
      "被重新分类数          31034\n",
      "被改变类别数     2043\n",
      "共从 216756 个步骤中检测到 212420 个异常值\n",
      "压缩比例: 98 ;类别改变比例 0.03055360449524296\n",
      "总序列数       31322\n",
      "被重新分类数          31257\n",
      "被改变类别数     957\n",
      "共从 216756 个步骤中检测到 214588 个异常值\n",
      "压缩比例: 99 ;类别改变比例 0.013856075601813423\n",
      "总序列数       31322\n",
      "被重新分类数          31292\n",
      "被改变类别数     434\n",
      "    changed_ratios  total_seqnum  reclassified_seqnum  changed_seqnum  \\\n",
      "0         0.028191         31322                 9274             883   \n",
      "1         0.040802         31322                12021            1278   \n",
      "2         0.056446         31322                14665            1768   \n",
      "3         0.074229         31322                17602            2325   \n",
      "4         0.089043         31322                20356            2789   \n",
      "5         0.101654         31322                23197            3184   \n",
      "6         0.123268         31322                26029            3861   \n",
      "7         0.145425         31322                28736            4555   \n",
      "8         0.122534         31322                30530            3838   \n",
      "9         0.065226         31322                31034            2043   \n",
      "10        0.030554         31322                31257             957   \n",
      "11        0.013856         31322                31292             434   \n",
      "\n",
      "    Null_seqnum  \n",
      "0             1  \n",
      "1             2  \n",
      "2            44  \n",
      "3           148  \n",
      "4           371  \n",
      "5           897  \n",
      "6          2467  \n",
      "7          6143  \n",
      "8         14572  \n",
      "9         21940  \n",
      "10        27221  \n",
      "11        29148  \n"
     ]
    }
   ],
   "source": [
    "total_loss_list,setting_loss_list,time_loss_list=LossCalculate(loaded_list,final_assignment_list,Model,models)#计算损失值\n",
    "changed_ratios=[0]*len(thresholds)\n",
    "total_seqnum=[0]*len(thresholds)\n",
    "reclassified_seqnum=[0]*len(thresholds)\n",
    "changed_seqnum=[0]*len(thresholds)\n",
    "Null_seqnum =[0]*len(thresholds)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    changed_ratios[i],total_seqnum[i],reclassified_seqnum[i],changed_seqnum[i],Null_seqnum[i]=LossPrune(loaded_list,final_assignment_list,models,threshold, total_loss_list,setting_loss_list,time_loss_list)#删除损失值最低的\n",
    "df_plot={\"changed_ratios\":changed_ratios,\"total_seqnum\":total_seqnum,\"reclassified_seqnum\":reclassified_seqnum,\"changed_seqnum\":changed_seqnum,\"Null_seqnum\":Null_seqnum}\n",
    "Tickets_df_plot = pd.DataFrame(data=df_plot)\n",
    "print(Tickets_df_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
